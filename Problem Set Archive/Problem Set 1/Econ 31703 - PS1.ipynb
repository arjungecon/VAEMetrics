{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import njit, jit\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from numpy import random\n",
    "from numpy import linalg\n",
    "from scipy import sparse\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import matplotlib\n",
    "import itertools as it\n",
    "from matplotlib import rc\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "matplotlib.rcParams['text.usetex'] = True\n",
    "matplotlib.rcParams['text.latex.preamble'] = [\n",
    "    r'\\usepackage{amssymb}',\n",
    "    r'\\usepackage{amsmath}',\n",
    "    r'\\usepackage{xcolor}',\n",
    "    r'\\renewcommand*\\familydefault{\\sfdefault}']\n",
    "matplotlib.rcParams['pgf.texsystem'] = 'pdflatex'\n",
    "matplotlib.rcParams['pgf.preamble']  = [\n",
    "    r'\\usepackage[utf8x]{inputenc}',\n",
    "    r'\\usepackage{amssymb}',\n",
    "    r'\\usepackage[T1]{fontenc}',\n",
    "    r'\\usepackage{amsmath}',\n",
    "    r'\\usepackage{sansmath}']\n",
    "\n",
    "from IPython.display import set_matplotlib_formats\n",
    "%matplotlib inline\n",
    "set_matplotlib_formats('svg')\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"ProblemSet1Exercise2data.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) \n",
    "The regression result is showing that the contribution of current GDP on GDP growth is negative while life expectancy and primary school enrollment rate have a positive effect on long-run growth. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  gamma   R-squared:                       0.288\n",
      "Model:                            OLS   Adj. R-squared:                  0.221\n",
      "Method:                 Least Squares   F-statistic:                     4.313\n",
      "Date:                Fri, 24 Apr 2020   Prob (F-statistic):             0.0116\n",
      "Time:                        15:48:43   Log-Likelihood:                 106.24\n",
      "No. Observations:                  36   AIC:                            -204.5\n",
      "Df Residuals:                      32   BIC:                            -198.2\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0615      0.024      2.534      0.016       0.012       0.111\n",
      "GDPSH60       -0.0160      0.005     -3.080      0.004      -0.027      -0.005\n",
      "LIFEE060       0.0013      0.001      2.379      0.023       0.000       0.002\n",
      "P60            0.0090      0.021      0.425      0.674      -0.034       0.052\n",
      "==============================================================================\n",
      "Omnibus:                        1.831   Durbin-Watson:                   1.634\n",
      "Prob(Omnibus):                  0.400   Jarque-Bera (JB):                0.894\n",
      "Skew:                           0.327   Prob(JB):                        0.639\n",
      "Kurtosis:                       3.412   Cond. No.                         698.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "X=data.loc[:, data.columns.isin(['GDPSH60','LIFEE060','P60'])]\n",
    "X = sm.add_constant(X)\n",
    "mod = sm.OLS(data.gamma, X)\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b)\n",
    "When we use all covariates in the dataset, we obtain a perfect fit with R-squared = 1. GDPSH60, LIFEE060, and P60 flip sign compared to the results found in (a). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  gamma   R-squared:                       1.000\n",
      "Model:                            OLS   Adj. R-squared:                    nan\n",
      "Method:                 Least Squares   F-statistic:                       nan\n",
      "Date:                Fri, 24 Apr 2020   Prob (F-statistic):                nan\n",
      "Time:                        15:48:43   Log-Likelihood:                 1076.4\n",
      "No. Observations:                  36   AIC:                            -2081.\n",
      "Df Residuals:                       0   BIC:                            -2024.\n",
      "Df Model:                          35                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0138        inf          0        nan         nan         nan\n",
      "GDPSH60        0.0112        inf          0        nan         nan         nan\n",
      "LIFEE060      -0.0004        inf         -0        nan         nan         nan\n",
      "P60           -0.0153        inf         -0        nan         nan         nan\n",
      "safrica        0.0287        inf          0        nan         nan         nan\n",
      "laam          -0.0062        inf         -0        nan         nan         nan\n",
      "bmp1           0.0125        inf          0        nan         nan         nan\n",
      "BMS6087    -3.686e-05        inf         -0        nan         nan         nan\n",
      "GDC6089       -0.0003        inf         -0        nan         nan         nan\n",
      "STDC6089      -0.0001        inf         -0        nan         nan         nan\n",
      "PI6089         0.0003        inf          0        nan         nan         nan\n",
      "STPI6089   -5.951e-05        inf         -0        nan         nan         nan\n",
      "SCOUT         -0.0058        inf         -0        nan         nan         nan\n",
      "area        4.934e-07        inf          0        nan         nan         nan\n",
      "freeop         0.0046        inf          0        nan         nan         nan\n",
      "freetar        0.0059        inf          0        nan         nan         nan\n",
      "dpop6090      -0.0014        inf         -0        nan         nan         nan\n",
      "pyr60          0.0114        inf          0        nan         nan         nan\n",
      "syr60          0.0201        inf          0        nan         nan         nan\n",
      "hyr60         -0.0106        inf         -0        nan         nan         nan\n",
      "human60        0.0216        inf          0        nan         nan         nan\n",
      "s60           -0.0035        inf         -0        nan         nan         nan\n",
      "h60           -0.0115        inf         -0        nan         nan         nan\n",
      "YrsOpen        0.0187        inf          0        nan         nan         nan\n",
      "ggcfd3        -0.0005        inf         -0        nan         nan         nan\n",
      "gvxdxe52       0.0060        inf          0        nan         nan         nan\n",
      "geerec1       -0.0012        inf         -0        nan         nan         nan\n",
      "gde1          -0.0014        inf         -0        nan         nan         nan\n",
      "assassp2      -0.0173        inf         -0        nan         nan         nan\n",
      "revcoup       -0.0044        inf         -0        nan         nan         nan\n",
      "pinstab2      -0.0128        inf         -0        nan         nan         nan\n",
      "wardum        -0.0059        inf         -0        nan         nan         nan\n",
      "prightsb      -0.0053        inf         -0        nan         nan         nan\n",
      "civlibb        0.0057        inf          0        nan         nan         nan\n",
      "ABSLATIT     1.43e-05        inf          0        nan         nan         nan\n",
      "FRAC          -0.0085        inf         -0        nan         nan         nan\n",
      "DEMOC65       -0.0136        inf         -0        nan         nan         nan\n",
      "PRIEXP70      -0.0139        inf         -0        nan         nan         nan\n",
      "RULELAW        0.0038        inf          0        nan         nan         nan\n",
      "URB60         -0.0084        inf         -0        nan         nan         nan\n",
      "RERD          -0.0002        inf         -0        nan         nan         nan\n",
      "EQINV         -0.0008        inf         -0        nan         nan         nan\n",
      "NONEQINV       0.0096        inf          0        nan         nan         nan\n",
      "humanyl       -0.0038        inf         -0        nan         nan         nan\n",
      "tot1           0.0028        inf          0        nan         nan         nan\n",
      "work60l        0.0185        inf          0        nan         nan         nan\n",
      "lly1          -0.0080        inf         -0        nan         nan         nan\n",
      "BRIT          -0.0053        inf         -0        nan         nan         nan\n",
      "FRENCH         0.0005        inf          0        nan         nan         nan\n",
      "SPAIN          0.0139        inf          0        nan         nan         nan\n",
      "BUDDHA        -0.0086        inf         -0        nan         nan         nan\n",
      "CATH          -0.0147        inf         -0        nan         nan         nan\n",
      "CONFUC         0.0379        inf          0        nan         nan         nan\n",
      "HINDU         -0.0097        inf         -0        nan         nan         nan\n",
      "JEW           -0.0007        inf         -0        nan         nan         nan\n",
      "MUSLIM         0.0092        inf          0        nan         nan         nan\n",
      "PROT          -0.0178        inf         -0        nan         nan         nan\n",
      "lforce60   -3.114e-08        inf         -0        nan         nan         nan\n",
      "Mining         0.0014        inf          0        nan         nan         nan\n",
      "EcOrg          0.0043        inf          0        nan         nan         nan\n",
      "OthFrac       -0.0074        inf         -0        nan         nan         nan\n",
      "EngFrac       -0.0029        inf         -0        nan         nan         nan\n",
      "==============================================================================\n",
      "Omnibus:                       27.430   Durbin-Watson:                   1.926\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               98.678\n",
      "Skew:                           1.468   Prob(JB):                     3.74e-22\n",
      "Kurtosis:                      10.560   Cond. No.                     5.14e+05\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The input rank is higher than the number of observations.\n",
      "[3] The condition number is large, 5.14e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "X=data.loc[:, ~data.columns.isin(['code','country','gamma'])]\n",
    "X = sm.add_constant(X)\n",
    "mod = sm.OLS(data.gamma, X)\n",
    "res = mod.fit()\n",
    "print(res.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c)\n",
    "We find that YrsOpen and PRIEXP70 are the two covariates that give the highest R-squared when they are used with the covariates GDPSH60, LIFEE060, and P60. The signs of baseline model covariates are the same as what we obtain in part (a). The signs of coefficients of newly added covariates show that the length of trade openness affects long-run growth positively while share of primary exports is the opposite. The signs are plausible as we know being open to trade is growth improving but exporting raw materials more suffers from declining terms of trade which can hinder the growth. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('YrsOpen', 'PRIEXP70')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comb = list(it.combinations(data.columns[~data.columns.isin(['code','country','gamma','GDPSH60','LIFEE060','P60'])],2))\n",
    "rsq=np.zeros(shape=(np.shape(np.array(comb))[0],1))\n",
    "count=0\n",
    "for i in it.combinations(data.columns[~data.columns.isin(['code','country','gamma','GDPSH60','LIFEE060','P60'])],2):\n",
    "    X=data.loc[:, data.columns.isin(i)]\n",
    "    X= np.column_stack((X,data.GDPSH60,data.LIFEE060,data.P60))\n",
    "    X = sm.add_constant(X)\n",
    "    modb = sm.OLS(data.gamma, X)\n",
    "    resb = modb.fit()\n",
    "    rsq[count] = resb.rsquared\n",
    "    count = count +1\n",
    "    \n",
    "maxrsq = np.argmax(rsq)\n",
    "comb[maxrsq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  gamma   R-squared:                       0.703\n",
      "Model:                            OLS   Adj. R-squared:                  0.654\n",
      "Method:                 Least Squares   F-statistic:                     14.21\n",
      "Date:                Fri, 24 Apr 2020   Prob (F-statistic):           3.70e-07\n",
      "Time:                        15:48:47   Log-Likelihood:                 121.99\n",
      "No. Observations:                  36   AIC:                            -232.0\n",
      "Df Residuals:                      30   BIC:                            -222.5\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.1415      0.022      6.499      0.000       0.097       0.186\n",
      "GDPSH60       -0.0212      0.004     -5.955      0.000      -0.028      -0.014\n",
      "LIFEE060       0.0006      0.000      1.426      0.164      -0.000       0.001\n",
      "P60            0.0185      0.016      1.195      0.241      -0.013       0.050\n",
      "YrsOpen        0.0254      0.006      4.069      0.000       0.013       0.038\n",
      "PRIEXP70      -0.0278      0.007     -4.101      0.000      -0.042      -0.014\n",
      "==============================================================================\n",
      "Omnibus:                        1.400   Durbin-Watson:                   2.076\n",
      "Prob(Omnibus):                  0.497   Jarque-Bera (JB):                0.570\n",
      "Skew:                          -0.242   Prob(JB):                        0.752\n",
      "Kurtosis:                       3.382   Cond. No.                         953.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "X=data.loc[:, ( data.columns.isin(comb[maxrsq])) | ( data.columns.isin(['GDPSH60','LIFEE060','P60']))]\n",
    "X = sm.add_constant(X)\n",
    "mod = sm.OLS(data.gamma, X)\n",
    "res = mod.fit()\n",
    "print(res.summary())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1653"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.size(rsq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d)\n",
    "In part (c) we run $\\frac{58!}{(58-2)!2!}=1653$ different regressions. If we want to choose 5 more additional variables instead of two, then we need $\\frac{58!}{(58-5)!5!}=4582116$  and for 6 additional variables we need $\\frac{58!}{(58-6)!6!}=40475358$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "def find_smallest_eig(rho,p,N,S):\n",
    "    covar_mat = np.ones((p,p)) *  rho\n",
    "    np.fill_diagonal(covar_mat,1)\n",
    "    smallest_eig = np.zeros(S)\n",
    "    for i in range(S):\n",
    "        X = np.random.multivariate_normal(np.zeros(p),covar_mat,N) \n",
    "        val, vec  = np.linalg.eig(np.matmul(np.transpose(X),X))\n",
    "        smallest_eig[i] = np.amin(val)\n",
    "    return np.mean(smallest_eig)\n",
    "\n",
    "N = np.array([100,200,500,1000])   \n",
    "rho = np.array([0,0.5,0.9])\n",
    "p = 90\n",
    "S = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a-b)\n",
    "Table below shows that when $\\rho$ increases the smallest eigenvalue decreases which means if collinearity between variables are high then we get higher variance in our estimate and also inverting the matrix may create some problems. Another feature we can observe is that when covariate number is fixed, then increasing the sample helps to get higher eigenvalues, so the smaller variance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>$\\rho = 0$</th>\n",
       "      <th>$\\rho = 0.5$</th>\n",
       "      <th>$\\rho = 0.9$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>$N = 100, p=90$</th>\n",
       "      <td>0.363860</td>\n",
       "      <td>0.183166</td>\n",
       "      <td>0.038164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$N = 200, p=90$</th>\n",
       "      <td>23.659328</td>\n",
       "      <td>11.745444</td>\n",
       "      <td>2.450264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$N = 500, p=90$</th>\n",
       "      <td>175.541705</td>\n",
       "      <td>86.079697</td>\n",
       "      <td>17.126195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$N = 1000, p=90$</th>\n",
       "      <td>504.993682</td>\n",
       "      <td>250.633126</td>\n",
       "      <td>50.826839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  $\\rho = 0$  $\\rho = 0.5$  $\\rho = 0.9$\n",
       "$N = 100, p=90$     0.363860      0.183166      0.038164\n",
       "$N = 200, p=90$    23.659328     11.745444      2.450264\n",
       "$N = 500, p=90$   175.541705     86.079697     17.126195\n",
       "$N = 1000, p=90$  504.993682    250.633126     50.826839"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eig_mat = np.zeros((np.size(N),np.size(rho)))\n",
    "\n",
    "for i in range(np.size(N)):\n",
    "    for j in range(np.size(rho)):\n",
    "        eig_mat[i,j] = find_smallest_eig(rho[j],p,N[i],S)\n",
    "        \n",
    "eig_table = pd.DataFrame(eig_mat)\n",
    "eig_table.columns = ['$\\rho = 0$','$\\rho = 0.5$','$\\rho = 0.9$']\n",
    "eig_table = eig_table.rename(index={0: \"$N = 100, p=90$\", 1: \"$N = 200, p=90$\", 2: \"$N = 500, p=90$\", 3: \"$N = 1000, p=90$\"})\n",
    "\n",
    "eig_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c)\n",
    "When the number of covariates used in the analysis depends on the sample size we see that the increase in eigenvalues with sample size is slower. This shows that increasing the number of covariates acts as an opposing force on eigenvalues. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>$\\rho = 0$</th>\n",
       "      <th>$\\rho = 0.5$</th>\n",
       "      <th>$\\rho = 0.9$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>$N = 100, p=90$</th>\n",
       "      <td>0.406568</td>\n",
       "      <td>0.233357</td>\n",
       "      <td>0.040771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$N = 200, p=180$</th>\n",
       "      <td>0.730736</td>\n",
       "      <td>0.315711</td>\n",
       "      <td>0.067149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$N = 500, p=450$</th>\n",
       "      <td>1.640309</td>\n",
       "      <td>0.801294</td>\n",
       "      <td>0.145375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$N = 1000, p=900$</th>\n",
       "      <td>2.809834</td>\n",
       "      <td>1.362788</td>\n",
       "      <td>0.281460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   $\\rho = 0$  $\\rho = 0.5$  $\\rho = 0.9$\n",
       "$N = 100, p=90$      0.406568      0.233357      0.040771\n",
       "$N = 200, p=180$     0.730736      0.315711      0.067149\n",
       "$N = 500, p=450$     1.640309      0.801294      0.145375\n",
       "$N = 1000, p=900$    2.809834      1.362788      0.281460"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eig_mat2 = np.zeros((np.size(N),np.size(rho)))\n",
    "\n",
    "for i in range(np.size(N)):\n",
    "    for j in range(np.size(rho)):\n",
    "        eig_mat2[i,j] = find_smallest_eig(rho[j],int(0.9*N[i]),N[i],S)\n",
    "    \n",
    "eig_table2 = pd.DataFrame(eig_mat2)\n",
    "eig_table2.columns = ['$\\rho = 0$','$\\rho = 0.5$','$\\rho = 0.9$']\n",
    "eig_table2 = eig_table2.rename(index={0: \"$N = 100, p=90$\", 1: \"$N = 200, p=180$\", 2: \"$N = 500, p=450$\", 3: \"$N = 1000, p=900$\"})\n",
    "\n",
    "eig_table2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### d)\n",
    " When the number of variables used in regression grows not linearly but logarithmic, we see less effect of increasing variable numbers on eigenvalues.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>$\\rho = 0$</th>\n",
       "      <th>$\\rho = 0.5$</th>\n",
       "      <th>$\\rho = 0.9$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>$N = 100, p=90$</th>\n",
       "      <td>0.408932</td>\n",
       "      <td>0.233821</td>\n",
       "      <td>0.040689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$N = 200, p=103$</th>\n",
       "      <td>17.611569</td>\n",
       "      <td>9.234064</td>\n",
       "      <td>1.729785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$N = 500, p=121$</th>\n",
       "      <td>135.331114</td>\n",
       "      <td>67.982816</td>\n",
       "      <td>13.407499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$N = 1000, p=135$</th>\n",
       "      <td>414.023602</td>\n",
       "      <td>206.798231</td>\n",
       "      <td>41.227573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   $\\rho = 0$  $\\rho = 0.5$  $\\rho = 0.9$\n",
       "$N = 100, p=90$      0.408932      0.233821      0.040689\n",
       "$N = 200, p=103$    17.611569      9.234064      1.729785\n",
       "$N = 500, p=121$   135.331114     67.982816     13.407499\n",
       "$N = 1000, p=135$  414.023602    206.798231     41.227573"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eig_mat3 = np.zeros((np.size(N),np.size(rho)))\n",
    "\n",
    "for i in range(np.size(N)):\n",
    "    for j in range(np.size(rho)):\n",
    "        eig_mat3[i,j] = find_smallest_eig(rho[j],int(np.floor(19.55*np.log(N[i]))),N[i],S)\n",
    "        \n",
    "eig_table3 = pd.DataFrame(eig_mat3)\n",
    "eig_table3.columns = ['$\\rho = 0$','$\\rho = 0.5$','$\\rho = 0.9$']\n",
    "eig_table3 = eig_table3.rename(index={0: \"$N = 100, p=90$\", 1: \"$N = 200, p=103$\", 2: \"$N = 500, p=121$\", 3: \"$N = 1000, p=135$\"})\n",
    "\n",
    "eig_table3      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
