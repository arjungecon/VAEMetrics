{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\tools\\_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from matplotlib import rc\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import zscore\n",
    "import scipy as sp\n",
    "from numpy import random, linalg\n",
    "from scipy import sparse, stats\n",
    "import itertools as it\n",
    "from sklearn.preprocessing import StandardScaler as scaler\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import KFold\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "\n",
    "\n",
    "matplotlib.rcParams['text.usetex'] = True\n",
    "matplotlib.rcParams['text.latex.preamble'] = [\n",
    "    r'\\usepackage{amssymb}',\n",
    "    r'\\usepackage{amsmath}',\n",
    "    r'\\usepackage{xcolor}',\n",
    "    r'\\renewcommand*\\familydefault{\\sfdefault}']\n",
    "matplotlib.rcParams['pgf.texsystem'] = 'pdflatex'\n",
    "matplotlib.rcParams['pgf.preamble'] = [\n",
    "    r'\\usepackage[utf8x]{inputenc}',\n",
    "    r'\\usepackage{amssymb}',\n",
    "    r'\\usepackage[T1]{fontenc}',\n",
    "    r'\\usepackage{amsmath}',\n",
    "    r'\\usepackage{sansmath}']\n",
    "\n",
    "inv, ax, norm = np.linalg.inv, np.newaxis, np.linalg.norm\n",
    "randint = np.random.randint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def lasso_objective(b, y, X, lmbda):\n",
    "\n",
    "    # Question 1 Part A\n",
    "\n",
    "    \"\"\"\n",
    "        Function that accepts the guess for the parameter vector and LASSO penalty multipler λ,\n",
    "         and computes the LASSO objective function based on the input data.\n",
    "        :param b: Parameter vector.\n",
    "        :param y: Outcome variable, vector of size N.\n",
    "        :param X: Covariate variables (may or may not include ι), matrix of size N x P.\n",
    "        :param lmbda: LASSO penalty.\n",
    "        :return: Objective function evaluated using inputs.\n",
    "    \"\"\"\n",
    "\n",
    "    # Return the objective function if matrix multiplication Xβ is compatible.\n",
    "    try:\n",
    "        obj = np.square(y - X @ b).sum()/(2*y.size) + lmbda * norm(b, ord=1)\n",
    "        return obj\n",
    "    except:\n",
    "        print(\"Error: The number of covariates is not compatible with given coefficient vector.\")\n",
    "        return np.inf\n",
    "\n",
    "\n",
    "def dual_sol(bj, lmbda):\n",
    "\n",
    "    \"\"\"\n",
    "        Function that returns the solution for a single coordinate in the Cyclic\n",
    "         Coordinate Descent algorithm given the OLS coordinate estimate and the\n",
    "         LASSO penalty multipler.\n",
    "        :param bj: OLS estimate for coordinate j.\n",
    "        :param lmbda: LASSO penalty multiplier.\n",
    "        :return: LASSO coordinate estimate.\n",
    "    \"\"\"\n",
    "\n",
    "    if bj < - lmbda:\n",
    "        return bj + lmbda\n",
    "    elif bj > lmbda:\n",
    "        return bj - lmbda\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def lambda_zero(y, X, standardized=False):\n",
    "\n",
    "    # Question 1 Part D\n",
    "\n",
    "    \"\"\"\n",
    "        Function that computes the smallest penalty at which the LASSO estimate is exactly equal to zero.\n",
    "        :param y: Outcome variable, vector of size N.\n",
    "        :param X: Covariate variables (may or may not include ι), matrix of size N x P.\n",
    "        :param standardized: Indicator for whether the data has been standardized.\n",
    "        :return: The lambda penalty.\n",
    "    \"\"\"\n",
    "\n",
    "    # Detect if a constant term is included\n",
    "    iota = (X[:, 0] == X[:, 0].mean()).all()\n",
    "\n",
    "    # Trim out constant term\n",
    "    if iota:\n",
    "        X = X[:, 1:]\n",
    "\n",
    "    if standardized is False:\n",
    "        X, y = zscore(X, axis=0), zscore(y)\n",
    "    lmbda_max = np.max(np.abs(y.T @ X) / y.size)\n",
    "\n",
    "    return lmbda_max\n",
    "\n",
    "\n",
    "def lasso_cdg(b_start, y, X, lmbda, eps=1e-7, max_iter=5000, standardized=False,\n",
    "              active_set=False, active_set_cycle=10, safe=False):\n",
    "\n",
    "    # Question 1 Part B + C + E\n",
    "\n",
    "    \"\"\"\n",
    "        Function that performs the LASSO estimation through the Cyclic Coordinate Descent algorithm. Additional\n",
    "         options for using the Active Set Strategy and the SAFE algorithm are provided.\n",
    "\n",
    "        :param b_start: Initial guess for the parameter vector (may or may not include b0, which will be \n",
    "         trimmed out if so)\n",
    "        :param y: Outcome variable, vector of size N.\n",
    "        :param X: Covariate variables (may or may not include ι), matrix of size N x P.\n",
    "        :param lmbda: LASSO penalty multiplier.\n",
    "        :param eps: Norm stopping criterion.\n",
    "        :param max_iter: Iteration number stopping criterion.\n",
    "        :param standardized: Indicator for whether the data has been standardized.\n",
    "\n",
    "        :param active_set: Option for using the Active Set strategy to increase the speed of the algorithm.\n",
    "        :param active_set_cycle: The frequency at which all covariates are updated in CDG rather than those in\n",
    "         the Active Set. This option is not used if \"active_set\" is False.\n",
    "        :param safe: Option for using the SAFE strategy to discard covariates.\n",
    "\n",
    "        :return: List containing:\n",
    "            - :estimate: final coefficient vector estimate,\n",
    "            - :objectives: vector containing LASSO objective function values\n",
    "            - :steps: vector containing norm of difference in estimated parameter vectors\n",
    "            - :status: string regarding which stopping criterion was used.\n",
    "    \"\"\"\n",
    "\n",
    "    p, N, b_guess = b_start.size, y.size, b_start\n",
    "    y_mean, y_std = y.mean(), y.std()\n",
    "\n",
    "    if N != X.shape[0]:\n",
    "        print(\"Error: Covariate matrix is incompatible with outcome variable.\")\n",
    "        return None\n",
    "    elif p != X.shape[1]:\n",
    "        print(\"Error: Covariate matrix is incompatible with parameter vector.\")\n",
    "        return None\n",
    "\n",
    "    # Detect if a constant term is included\n",
    "    iota = (X[:, 0] == X[:, 0].mean()).all()\n",
    "\n",
    "    # Trim out constant term\n",
    "    if iota:\n",
    "        X, b_guess = X[:, 1:], b_guess[1:]\n",
    "        p = p - 1\n",
    "\n",
    "    # Computing sample mean and std. dev. for the pre-standardized data.\n",
    "    X_mean, X_std = X.mean(axis=0), X.std(axis=0)\n",
    "\n",
    "    # Standardize data if not done so\n",
    "    if standardized is False:\n",
    "        X, y = zscore(X, axis=0), zscore(y)\n",
    "        # X, y = (X - X.mean(axis=0)[ax, :])/X.std(axis=0)[ax, :], y - y.mean()\n",
    "\n",
    "    # LASSO objective\n",
    "    lasso_obj = lambda b: lasso_objective(b, y, X, lmbda)\n",
    "\n",
    "    # Default options for Active Set and SAFE strategies\n",
    "    active_range = lambda x: np.arange(0, p)\n",
    "    safe_range = np.arange(0, p)\n",
    "\n",
    "    # Implementing Active Set Strategy\n",
    "    if active_set:\n",
    "        active_range = lambda x: np.where(x != 0)[0]\n",
    "\n",
    "    # Implementing SAFE Strategy\n",
    "    if safe:\n",
    "\n",
    "        # Find lambda_max: minimum value of lambda such that LASSO estimate is zero\n",
    "        lmbda_max = lambda_zero(y=y, X=X, standardized=True)\n",
    "\n",
    "        # Assign Boolean condition for covariates that can be discarded using the SAFE condition\n",
    "        safe_condition = (X.T @ y).squeeze() < lmbda - norm(X, axis=0) * norm(y) * (lmbda_max - lmbda)/lmbda\n",
    "\n",
    "        # Find indices corresponding to \"relevant\" covariates\n",
    "        safe_range = np.where(~safe_condition)[0]\n",
    "\n",
    "        # Set discarded covariates to have zero estimate under LASSO\n",
    "        b_guess[safe_condition] = 0\n",
    "\n",
    "    # Empty dictionary to store results of LASSO estimation for a given value of lambda.\n",
    "    key_dict = {\"estimate\", \"objectives\", \"steps\", \"status\"}\n",
    "    output = dict([(key, []) for key in key_dict])\n",
    "\n",
    "    niter, dist = 0, 1000\n",
    "\n",
    "    # While loop to perform LASSO minimization using two stopping criterion.\n",
    "    while niter < max_iter and dist > eps:\n",
    "\n",
    "        b_update = np.zeros(shape=b_guess.shape)\n",
    "\n",
    "        # Active set strategy\n",
    "        if niter % active_set_cycle == 0:\n",
    "\n",
    "            # Using SAFE range for every active_set_cycle number of iterations.\n",
    "            range_j = safe_range\n",
    "\n",
    "        else:\n",
    "\n",
    "            # Apply active-set range.\n",
    "            range_j = active_range(b_guess)\n",
    "\n",
    "        for j in range_j:\n",
    "\n",
    "            # Extract j^{th} covariate vector\n",
    "            Xj = X[:, j].reshape(-1, 1)\n",
    "\n",
    "            # Compute OLS solution for β_j taking β_{-j} as given\n",
    "            bj = b_guess[j] + Xj.T @ (y - X @ b_guess)/N\n",
    "\n",
    "            # Update guess for j^{th} coordinate using LASSO closed form solution under CDG.\n",
    "            b_update[j] = dual_sol(bj, lmbda)\n",
    "\n",
    "        # Compute the distance between the successive LASSO estimates.\n",
    "        b0 = y_mean - np.dot(X_mean, b_update)\n",
    "        dist = norm(b_update - b_guess, ord=np.inf)\n",
    "\n",
    "        output[\"estimate\"].append(np.append(b0, b_update))\n",
    "        output[\"objectives\"].append(lasso_obj(b_update))\n",
    "        output[\"steps\"].append(dist)\n",
    "\n",
    "        niter = niter + 1\n",
    "\n",
    "        # Update guess for LASSO estimate in the next cycle of CDG.\n",
    "        b_guess = b_update\n",
    "\n",
    "        if dist <= eps:\n",
    "            output[\"status\"] = \"convergence\"\n",
    "\n",
    "    if niter >= max_iter:\n",
    "        output[\"status\"] = \"max_iter exceed\"\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def lasso_wrapper_sequential(b_start, y, X, standardized=False, num_lambda=100, min_factor=0.001,\n",
    "                             warm_start=False, k_fold=False, num_k=5):\n",
    "\n",
    "    # Question 1 Part F (a) + (b) + G\n",
    "\n",
    "    \"\"\"\n",
    "        Function that performs the LASSO estimation through CDG + Active Set + SAFE for a pre-determined\n",
    "         sequence of λ. Includes option to use the warm start feature for the initial guess of the LASSO\n",
    "         estimate in successive iterations over λ values, and for K-fold cross-validation.\n",
    "\n",
    "        :param b_start: Initial guess for the parameter vector (may or may not include b0, which will be\n",
    "         trimmed out if so)\n",
    "        :param y: Outcome variable, vector of size N.\n",
    "        :param X: Covariate variables (may or may not include ι), matrix of size N x P.\n",
    "        :param standardized: Indicator for whether the data has been standardized.\n",
    "\n",
    "        :param num_lambda: Number of λ values to include in the sequence.\n",
    "        :param min_factor: The minimum value of λ as a fraction of λ_max\n",
    "\n",
    "        :param warm_start: Option for using warm start initial conditions.\n",
    "\n",
    "        As such the lambda sequence is given by:\n",
    "        Sequence(λ) = log([λ_max * min_factor : num_lambda : λ_max])\n",
    "\n",
    "        :param k_fold: Option to compute cross-validation results of lambda in a K-fold CV algorithm.\n",
    "        :param num_k: The number of K-folds to use. Used only when k_fold is True.\n",
    "\n",
    "        :return: List containing:\n",
    "            - :estimate: Final coefficient vector estimates across different λ values,\n",
    "            - :objectives: Vector containing LASSO objective across different λ values,\n",
    "            - :lambda: string regarding which stopping criterion was used.\n",
    "    \"\"\"\n",
    "\n",
    "    # Computing maximum lambda before LASSO estimate is exactly zero.\n",
    "    lmbda_max = lambda_zero(y, X, standardized=standardized)\n",
    "\n",
    "    print('max = {}'.format(lmbda_max))\n",
    "\n",
    "    # Computing sequence of lambdas over which LASSO is run based on the specification.\n",
    "    lmbda_vec = np.linspace(start=min_factor, stop=1, num=num_lambda) * lmbda_max\n",
    "\n",
    "    if k_fold is False:  # Running procedure with no K-fold cross-validation.\n",
    "\n",
    "        # Empty dictionary to store results for each value of lambda.\n",
    "        key_dict = {\"lambda\", \"estimate\", \"objective\", \"status\"}\n",
    "        output = dict([(key, []) for key in key_dict])\n",
    "\n",
    "        # Looping over the lambda vector.\n",
    "        for il, lmbda in enumerate(np.flipud(lmbda_vec)):\n",
    "\n",
    "            # Running lasso_cdg for the given value of lambda. We use both the active_set and SAFE strategies.\n",
    "            lasso_est = lasso_cdg(b_start, y, X, lmbda, eps=1e-6, max_iter=1000, standardized=standardized,\n",
    "                                  active_set=True, active_set_cycle=10, safe=True)\n",
    "\n",
    "            output[\"lambda\"].append(lmbda)\n",
    "            output[\"estimate\"].append(lasso_est['estimate'][-1])\n",
    "            output[\"objective\"].append(lasso_est['objectives'][-1])\n",
    "            output[\"status\"].append(lasso_est['status'])\n",
    "\n",
    "            if warm_start:\n",
    "\n",
    "                b_start = lasso_est['estimate'][-1][:, ax]\n",
    "\n",
    "    else:  # Running procedure with K-fold cross-validation of lambda.\n",
    "\n",
    "        # Empty dictionary to store CV error for each value of lambda.\n",
    "        key_dict = {\"lambda\", \"CVError\"}\n",
    "        output = dict([(key, []) for key in key_dict])\n",
    "\n",
    "        kf = KFold(n_splits=num_k)\n",
    "        iota = (X[:, 0] == X[:, 0].mean()).all()\n",
    "        b_start_k = [b_start] * num_k\n",
    "\n",
    "        # Looping over the lambda vector.\n",
    "\n",
    "        for il, lmbda in enumerate(np.flipud(lmbda_vec)):\n",
    "\n",
    "            split_num, cv_error_k = 0, np.zeros(num_k)\n",
    "\n",
    "            # Looping over each K-fold\n",
    "\n",
    "            for train_index, test_index in kf.split(X):\n",
    "\n",
    "                # Training to obtain LASSO estimate for the given lambda\n",
    "\n",
    "                X_train, y_train = X[train_index, :], y[train_index]\n",
    "\n",
    "                lasso_res_k = lasso_cdg(b_start=b_start_k[split_num], y=y_train, X=X_train, lmbda=lmbda,\n",
    "                                        standardized=standardized,\n",
    "                                        active_set=True, active_set_cycle=10, safe=True)\n",
    "\n",
    "                lasso_est_k = lasso_res_k['estimate'][-1]\n",
    "\n",
    "                if warm_start:\n",
    "\n",
    "                    b_start_k[split_num] = lasso_est_k[:, ax]\n",
    "\n",
    "                # Using the test data to construct the prediction error\n",
    "\n",
    "                X_test, y_test = X[test_index, :], y[test_index]\n",
    "\n",
    "                cv_error_k[split_num] = np.mean(np.square(y_test - X_test @ lasso_est_k[~iota * 1:]))\n",
    "\n",
    "                split_num = split_num + 1\n",
    "\n",
    "            # Storing the lambda value and the CV error\n",
    "\n",
    "            output[\"lambda\"].append(lmbda)\n",
    "            output[\"CVError\"].append(cv_error_k.sum())\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def lasso_wrapper_parallel(b_start, y, X, standardized=False, num_lambda=100, min_factor=0.001,\n",
    "                           k_fold=False, num_k=5):\n",
    "\n",
    "    # Question 1 Part F (a) + (b) + G\n",
    "\n",
    "    \"\"\"\n",
    "        Function that performs the LASSO estimation through CDG + Active Set + SAFE for a pre-determined\n",
    "         sequence of λ. Includes option for K-fold cross-validation.\n",
    "\n",
    "        :param b_start: Initial guess for the parameter vector (may or may not include b0, which will be\n",
    "         trimmed out if so)\n",
    "        :param y: Outcome variable, vector of size N.\n",
    "        :param X: Covariate variables (may or may not include ι), matrix of size N x P.\n",
    "        :param standardized: Indicator for whether the data has been standardized.\n",
    "\n",
    "        :param num_lambda: Number of λ values to include in the sequence.\n",
    "        :param min_factor: The minimum value of λ as a fraction of λ_max\n",
    "\n",
    "        :param warm_start: Option for using warm start initial conditions.\n",
    "\n",
    "        As such the lambda sequence is given by:\n",
    "        Sequence(λ) = log([λ_max * min_factor : num_lambda : λ_max])\n",
    "\n",
    "        :param k_fold: Option to compute cross-validation results of lambda in a K-fold CV algorithm.\n",
    "        :param num_k: The number of K-folds to use. Used only when k_fold is True.\n",
    "\n",
    "        :return: List containing:\n",
    "            - :estimate: Final coefficient vector estimates across different λ values,\n",
    "            - :objectives: Vector containing LASSO objective across different λ values,\n",
    "            - :lambda: string regarding which stopping criterion was used.\n",
    "    \"\"\"\n",
    "\n",
    "    def parallel_cdg(lmbda_index):\n",
    "\n",
    "        \"\"\"\n",
    "            :param lmbda_index: Index of the lambda vector corresponding to the lambda value\n",
    "             used in parallelization of the LASSO algorithm.\n",
    "        \"\"\"\n",
    "\n",
    "        lmbda = lmbda_vec[lmbda_index]\n",
    "\n",
    "        # Running lasso_cdg for the given value of lambda. We use both the active_set and SAFE strategies.\n",
    "        lasso_est = lasso_cdg(b_start, y, X, lmbda, eps=1e-6, max_iter=1000, standardized=standardized,\n",
    "                              active_set=True, active_set_cycle=10, safe=True)\n",
    "\n",
    "        return [lasso_est['estimate'][-1], lasso_est['objectives'][-1], lasso_est['status']]\n",
    "\n",
    "    def parallel_k_fold(lmbda_index):\n",
    "        \"\"\"\n",
    "            :param lmbda_index: Index of the lambda vector corresponding to the lambda value\n",
    "             used in parallelization of the LASSO cross-validation algorithm.\n",
    "        \"\"\"\n",
    "\n",
    "        lmbda, split_num, cv_error_k = lmbda_vec[lmbda_index], 0, np.zeros(num_k)\n",
    "        kf = KFold(n_splits=num_k)\n",
    "        iota = (X[:, 0] == X[:, 0].mean()).all()\n",
    "\n",
    "        # Looping over each K-fold\n",
    "\n",
    "        for train_index, test_index in kf.split(X):\n",
    "\n",
    "            # Training to obtain LASSO estimate for the given lambda\n",
    "\n",
    "            X_train, y_train = X[train_index, :], y[train_index]\n",
    "\n",
    "            lasso_res_k = lasso_cdg(b_start=b_start, y=y_train, X=X_train, lmbda=lmbda,\n",
    "                                    standardized=standardized,\n",
    "                                    active_set=True, active_set_cycle=10, safe=True)\n",
    "\n",
    "            lasso_est_k = lasso_res_k['estimate'][-1]\n",
    "\n",
    "            # Using the test data to construct the prediction error\n",
    "\n",
    "            X_test, y_test = X[test_index, :], y[test_index]\n",
    "\n",
    "            cv_error_k[split_num] = np.mean(np.square(y_test - X_test @ lasso_est_k[~iota * 1:]))\n",
    "\n",
    "            split_num = split_num + 1\n",
    "\n",
    "        return [lmbda, cv_error_k.sum()]\n",
    "\n",
    "    # Computing maximum lambda before LASSO estimate is exactly zero.\n",
    "    lmbda_max = lambda_zero(y, X, standardized=standardized)\n",
    "\n",
    "\n",
    "\n",
    "    # Computing sequence of lambdas over which LASSO is run based on the specification.\n",
    "    lmbda_vec = np.flipud(np.linspace(start=min_factor, stop=1, num=num_lambda) * lmbda_max)\n",
    "\n",
    "    # Number of cores used in parallelization.\n",
    "    num_cores = multiprocessing.cpu_count()\n",
    "\n",
    "    if k_fold is False:\n",
    "\n",
    "        output = Parallel(n_jobs=num_cores)(delayed(parallel_cdg)(i) for i in range(num_lambda))\n",
    "\n",
    "        return output\n",
    "\n",
    "    else:\n",
    "\n",
    "        output_CV = Parallel(n_jobs=num_cores)(delayed(parallel_k_fold)(i) for i in range(num_lambda))\n",
    "        lmbda_CV = np.array(output_CV)[np.argmin(np.array(output_CV)[:, 1]), 0]\n",
    "\n",
    "        lasso_CV = lasso_cdg(b_start=b_start, y=y, X=X, lmbda=lmbda_CV,\n",
    "                                    standardized=standardized,\n",
    "                                    active_set=True, active_set_cycle=10, safe=True)\n",
    "\n",
    "        return output_CV, lmbda_CV, lasso_CV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateData_paper(N, p, sigmax): \n",
    "  # generate X\n",
    "    X = random.multivariate_normal(size=N, mean=np.zeros(p), cov=(sigmax**2)*np.identity(p))\n",
    "  # generate epsilon\n",
    "    e = np.random.normal(size=N)\n",
    "  # coefficient vector\n",
    "    b = np.append(np.ones(5),np.zeros(p-5))\n",
    "  # generate Y\n",
    "    Y = X @ b + e\n",
    "\n",
    "    dat=pd.concat([pd.DataFrame(Y,columns=['Y']),pd.DataFrame(X,columns=[i + j for i, j in zip(['X']*(p),map(str,list(range(1,p+1))))])],axis=1)\n",
    "\n",
    "  # return dataset\n",
    "    return(dat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rep_figure1_lasso(N,p,sigma_vec,S):\n",
    "    l2 = np.zeros((3,sigma_vec.shape[0],S))\n",
    "    cov_num = np.zeros((3,sigma_vec.shape[0],S))\n",
    "    for k in range(S):\n",
    "        for j in range(sigma_vec.shape[0]):\n",
    "            data = generateData_paper(N, p, sigma_vec[j])\n",
    "            lmbda = 2 * np.power((2.01*(sigma_vec[j]**2)*np.log(p)/N),1/2)\n",
    "            lmbda_vec = np.array((lmbda, 2/3*lmbda, 1/3*lmbda ))\n",
    "            for i in range(3):\n",
    "                lasso = lasso_cdg(b_start=np.ones(p),y=data.Y, X=data[data.drop(['Y'], axis=1).columns].to_numpy(),lmbda=lmbda_vec[i],standardized=True)\n",
    "                l2[i,j,k] = norm(lasso[\"estimate\"][-1][1:]-np.append(np.ones(5),np.zeros(p-5)),ord=2)\n",
    "                cov_num[i,j,k] =(np.nonzero(lasso[\"estimate\"][-1])[0]).shape[0]-1\n",
    "    return (l2,cov_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 500\n",
    "p = 200\n",
    "sigma_vec = np.array((1/2,1/3,1/4,1/5,1/6,1/7))\n",
    "S=2\n",
    "rs=rep_figure1_lasso(N,p,sigma_vec,S)\n",
    "meanl2=np.mean(rs[0],axis=2)\n",
    "meancov=np.mean(rs[1],axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rep_figure2_lasso(N,p,sigma_vec,S):\n",
    "    bias = np.zeros((3,sigma_vec.shape[0],S))\n",
    "    cover = np.zeros((3,sigma_vec.shape[0],S))\n",
    "    interval = np.zeros((3,sigma_vec.shape[0],S))\n",
    "    for k in range(S):\n",
    "        for j in range(sigma_vec.shape[0]):\n",
    "            data = generateData_paper(N, p, sigma_vec[j])\n",
    "            lmbda = 2 * np.power((2.01*(sigma_vec[j]**2)*np.log(p)/N),1/2)\n",
    "            lmbda_vec = np.array((lmbda, 2/3*lmbda, 1/3*lmbda ))\n",
    "            for i in range(3):\n",
    "                lasso = doubleLasso_estimateCoefficients_fixedLambda(data, lmbda_vec[i], 0.05)\n",
    "                bias[i,j,k] = lasso['estimate']\n",
    "                cover[i,j,k] =(lasso['lb'] <= 1) * (1 <= lasso['ub'])\n",
    "                interval[i,j,k] =  lasso['ub'] - lasso['lb'] \n",
    "    return (bias,cover,interval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-8ff58c2387ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msigma_vec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mS\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrep_figure2_lasso\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msigma_vec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mmeanbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mmeancover\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-cbdf6fd59e2d>\u001b[0m in \u001b[0;36mrep_figure2_lasso\u001b[1;34m(N, p, sigma_vec, S)\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[0mlmbda_vec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlmbda\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlmbda\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlmbda\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m                 \u001b[0mlasso\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdoubleLasso_estimateCoefficients_fixedLambda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlmbda_vec\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.05\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m                 \u001b[0mbias\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlasso\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'estimate'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[0mcover\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlasso\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lb'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mlasso\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ub'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-24-14a7f15f264a>\u001b[0m in \u001b[0;36mdoubleLasso_estimateCoefficients_fixedLambda\u001b[1;34m(dat, lmbda, alpha)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m#First Lasso\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mlasso1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlasso_cdg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Y'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'X1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlmbda\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlmbda\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m#List of covariates from the first lasso\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "N = 500\n",
    "p = 200\n",
    "sigma_vec = np.array((1/2,1/3,1/4,1/5,1/6,1/7))\n",
    "S=2\n",
    "rs=rep_figure2_lasso(N,p,sigma_vec,S)\n",
    "meanbias=np.mean(rs[0],axis=2)\n",
    "meancover=np.mean(rs[1],axis=2)\n",
    "meaninterval=np.mean(rs[1],axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"Figure 1 for Lasso:\")\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5),  dpi=400, sharey='row')\n",
    "\n",
    "label=[]\n",
    "n=3\n",
    "lmbda=np.array(('1','2/3','1/3'))\n",
    "inv_sigma=np.array((2,3,4,5,6,7))\n",
    "ax[0].set_prop_cycle('color',[plt.cm.coolwarm(i) for i in np.linspace(0, 1, n)])\n",
    "for k in range(n):\n",
    "    ax[0].plot(inv_sigma,meanl2[:,k],'--',marker=\"o\",markersize=5)\n",
    "    label=label+['${}\\lambda$ '.format(lmbda[k])]\n",
    "ax[0].legend(label,fontsize=8)\n",
    "ax[0].set_xlabel(r\"$1/\\sigma_x$\")\n",
    "ax[0].set_ylabel(r\"Estimation Error\")\n",
    "\n",
    "\n",
    "n=3\n",
    "ax[1].set_prop_cycle('color',[plt.cm.coolwarm(i) for i in np.linspace(0, 1, n)])\n",
    "for k in range(n):\n",
    "    ax[1].plot(inv_sigma,meancov[:,k],'--',marker=\"o\",markersize=5)\n",
    "    label=label+['${}\\lambda$ '.format(lmbda[k])]\n",
    "ax[1].legend(label,fontsize=8)\n",
    "ax[1].set_xlabel(r\"$1/\\sigma_x$\")\n",
    "ax[1].set_ylabel(r\"Number of Selected Regressors\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateData_paper2(N, p, sigmax): \n",
    "  # generate X\n",
    "    X = random.multivariate_normal(size=N, mean=np.zeros(p), cov=(sigmax**2)*np.identity(p))\n",
    "  # generate epsilon\n",
    "    e = np.random.normal(size=N)\n",
    "    v = np.random.normal(size=N)\n",
    "  # coefficient vector\n",
    "    b = np.append(np.ones(5),np.zeros(p-5))\n",
    "    gamma = np.append(np.ones(5),np.zeros(p-5))\n",
    "  # generate Y\n",
    "    Y = X @ b + e\n",
    "    D = X @ gamma + v\n",
    "\n",
    "    dat=pd.concat([pd.DataFrame(Y,columns=['Y']),pd.DataFrame(D,columns=['D']),pd.DataFrame(X,columns=[i + j for i, j in zip(['X']*(p),map(str,list(range(1,p+1))))])],axis=1)\n",
    "\n",
    "  # return dataset\n",
    "    return(dat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_generateData(N, rho): \n",
    "  # generate X\n",
    "    X1 = np.random.normal(size=N)\n",
    "    X2 = rho * X1 + np.sqrt(1-rho**2) * np.random.normal(size=N)\n",
    "  \n",
    "  # generate Y\n",
    "    Y = X1 + (1/np.sqrt(N)) * X2 + np.random.normal(size=N)\n",
    "    data = {'Y': Y, 'X1': X1, 'X2': X2}\n",
    "    df = pd.DataFrame (data, columns = ['Y','X1','X2'],index=range(N))\n",
    "\n",
    "  # return dataset\n",
    "    return(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretest_estimateCoefficients(dat, alpha):\n",
    "    # read dimensions\n",
    "    N = dat.shape[0]\n",
    "    dn= 1/(N**(1/4))\n",
    "    X=dat.loc[:, dat.columns.isin(['X1','X2'])]\n",
    "    mod = sm.OLS(dat.Y, X)\n",
    "    res = mod.fit()  \n",
    "    keyDict = {\"coefficient\",\"lb\",\"ub\",\"test\"}\n",
    "    output = dict([(key, []) for key in keyDict])\n",
    "    if np.abs(res.params[1])>dn:\n",
    "        output['coefficient']=res.params[0]\n",
    "        output['lb']=res.conf_int(alpha=alpha, cols=None)[0][0]\n",
    "        output['ub']=res.conf_int(alpha=alpha, cols=None)[1][0]\n",
    "        output['test']= False\n",
    "    else:\n",
    "        X=dat.X1\n",
    "        mod = sm.OLS(dat.Y, X)\n",
    "        res = mod.fit()  \n",
    "        output['coefficient']=res.params[0]\n",
    "        output['lb']=res.conf_int(alpha=alpha, cols=None)[0][0]\n",
    "        output['ub']=res.conf_int(alpha=alpha, cols=None)[1][0]\n",
    "        output['test']= True    \n",
    "    return output \n",
    "\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretest_simulateCoefficients(N, rho, alpha, S):\n",
    "    results = pd.DataFrame(columns=(\"coefficient\",\"lb\",\"ub\",\"test\"))\n",
    "    # perform Monte Carlo simulation\n",
    "    for k in range(S): \n",
    "        dat = sim_generateData(N, rho)\n",
    "        results=pd.concat([results,pd.DataFrame(pretest_estimateCoefficients(dat, alpha),index=[k])])\n",
    "\n",
    "    return(results)\n",
    "\n",
    "# set seed\n",
    "random.seed(100)\n",
    "# specify model\n",
    "# list of N values\n",
    "N_array = np.array((100, 200, 400, 700, 1000))\n",
    "# correlation between X's\n",
    "rho = 0.9\n",
    "# significance level\n",
    "alpha = 0.05\n",
    "# number of Monte Carlo replications\n",
    "S = 1000\n",
    "\n",
    "result = pd.DataFrame(columns=(\"N\",\"coverageProb\",\"shortModelSelectionProb\"))\n",
    "k=0\n",
    "# perform simulation\n",
    "for i in N_array:\n",
    "\n",
    "    # simulate pretest estimators\n",
    "    results = pretest_simulateCoefficients(N=i, rho=rho, alpha=alpha, S=S)\n",
    "    # check if each confidence interval contains the true value\n",
    "    includeTrueValue = (results['lb'] <= 1) * (1 <= results['ub'])\n",
    "    # return the result\n",
    "    result=pd.concat([result,pd.DataFrame({\"N\":i,\"coverageProb\":includeTrueValue.mean(),\"shortModelSelectionProb\":results['test'].mean()},index=[k])])\n",
    "    k=k+1\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_generateData2(N, p, rho):\n",
    "    # generate X\n",
    "    X1 = np.random.normal(size=N)\n",
    "    Xp = (rho / (p-1)) * np.transpose([X1]*(p-1))+ np.sqrt(0.5 * (1-rho**2) / (p-1)) * np.random.normal(size=(N,p-1))\n",
    "    # generate Y\n",
    "    # bind Y and X\n",
    "    Y = X1 + ((1/np.sqrt(N)) * Xp).sum() + np.sqrt(0.5 * (1-rho**2)) * np.random.normal(size=N)\n",
    "    dat=pd.concat([pd.DataFrame(Y,columns=['Y']),pd.DataFrame(X1,columns=['X1']),pd.DataFrame(Xp,columns=[i + j for i, j in zip(['X']*(p-1),map(str,list(range(2,p+1))))])],axis=1)\n",
    "    \n",
    "    return(dat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doubleLasso_estimateCoefficients_fixedLambda(dat, lmbda, alpha):\n",
    "  \n",
    "    # read dimensions\n",
    "    N = dat.shape[0]\n",
    "    p = dat.shape[1] - 1\n",
    "    keyDict = {\"coefficient\", \"lb\", \"ub\", \"nreg\"}\n",
    "    output = dict([(key, []) for key in keyDict])\n",
    "    \n",
    "    #First Lasso\n",
    "    lasso1 = lasso_cdg(b_start=np.ones(p-1),y=dat.Y, X=dat[dat.drop(['Y','X1'], axis=1).columns].to_numpy(),lmbda=lmbda[0])\n",
    "\n",
    "    #List of covariates from the first lasso\n",
    "    cov1 = dat[dat.drop(['Y'], axis=1).columns].columns[np.nonzero(lasso1[\"estimate\"][-1])[0].tolist()]\n",
    "    \n",
    "    #Second Lasso\n",
    "    lasso2 = lasso_cdg(b_start=np.ones(p-1),y=dat.X1, X=dat[dat.drop(['Y','X1'], axis=1).columns].to_numpy(),lmbda=lmbda[1])\n",
    "\n",
    "    #List of covariates from the second lasso\n",
    "    cov2 = dat[dat.drop(['Y'], axis=1).columns].columns[np.nonzero(lasso2[\"estimate\"][-1])[0].tolist()]\n",
    "    \n",
    "    #Covariates from first or second lasso \n",
    "    X = dat.loc[:, dat.columns.isin(cov1) | dat.columns.isin(cov2)]\n",
    "    #OLS\n",
    "    mod = sm.OLS(dat.Y, X)\n",
    "    res = mod.fit() \n",
    "    output['coefficient']=res.params[0]\n",
    "    output['lb']=res.conf_int(alpha=alpha, cols=None)[0][0]\n",
    "    output['ub']=res.conf_int(alpha=alpha, cols=None)[1][0]\n",
    "    output['nreg']=res.params.shape[0]-1\n",
    "    \n",
    "    return output\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-3687f1cd92a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;31m# simulate pretest estimators\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdoubleLasso_simulateCoefficients_fixedLambda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrho\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrho\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlmbda\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlmbda\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mS\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m     \u001b[1;31m# check if each confidence interval contains the true value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[0mincludeTrueValue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lb'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ub'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-29-3687f1cd92a4>\u001b[0m in \u001b[0;36mdoubleLasso_simulateCoefficients_fixedLambda\u001b[1;34m(N, p, rho, lmbda, alpha, S)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mdat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msim_generateData2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrho\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mresults\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoubleLasso_estimateCoefficients_fixedLambda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlmbda\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-28-14a7f15f264a>\u001b[0m in \u001b[0;36mdoubleLasso_estimateCoefficients_fixedLambda\u001b[1;34m(dat, lmbda, alpha)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m#First Lasso\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mlasso1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlasso_cdg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Y'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'X1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlmbda\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlmbda\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m#List of covariates from the first lasso\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-2f2c102a6a21>\u001b[0m in \u001b[0;36mlasso_cdg\u001b[1;34m(b_start, y, X, lmbda, eps, max_iter, standardized, active_set, active_set_cycle, safe)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         \u001b[1;31m# Compute the distance between the successive LASSO estimates.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[0mb0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_mean\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb_update\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m         \u001b[0mdist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb_update\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mb_guess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mord\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def doubleLasso_simulateCoefficients_fixedLambda(N, p, rho, lmbda, alpha, S):\n",
    "  \n",
    "    # prepare storage space\n",
    "    results = pd.DataFrame(columns=(\"coefficient\",\"lb\",\"ub\",\"nreg\"))\n",
    "\n",
    "  \n",
    "    # perform Monte Carlo simulation\n",
    "    for k in range(S):\n",
    "        dat = sim_generateData2(N, p, rho)\n",
    "        results=pd.concat([results,pd.DataFrame(doubleLasso_estimateCoefficients_fixedLambda(dat, lmbda, alpha),index=[k])])\n",
    "\n",
    "  \n",
    "    return(results)\n",
    "\n",
    "\n",
    "\n",
    "# set seed\n",
    "random.seed(100)\n",
    "\n",
    "# specify model\n",
    "# list of N values\n",
    "N_array = np.array((100, 200, 400, 700, 1000))\n",
    "# number of regressors\n",
    "p = 3\n",
    "# correlation between X's\n",
    "rho = 0.9\n",
    "# lasso penalty multipliers\n",
    "lmbda = np.array((0.7, 0.7))\n",
    "# significance level\n",
    "alpha = 0.05\n",
    "# number of Monte Carlo replications\n",
    "S = 1000\n",
    "\n",
    "result = pd.DataFrame(columns=(\"N\",\"coverageProb\",\"meanAdditionalRegressors\"))\n",
    "k=0\n",
    "# perform simulation\n",
    "for i in N_array:\n",
    "\n",
    "    # simulate pretest estimators\n",
    "    results = doubleLasso_simulateCoefficients_fixedLambda(N=i, p=p, rho=rho, lmbda=lmbda, alpha=alpha, S=S)\n",
    "    # check if each confidence interval contains the true value\n",
    "    includeTrueValue = (results['lb'] <= 1) * (1 <= results['ub'])\n",
    "    # return the result\n",
    "    result=pd.concat([result,pd.DataFrame({\"N\":i,\"coverageProb\":includeTrueValue.mean(),\"meanAdditionalRegressors\":results['nreg'].mean()},index=[k])])\n",
    "    k=k+1\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doubleLasso_estimateCoefficients_cvLambda(dat, alpha):\n",
    " \n",
    "    # read dimensions\n",
    "    N = dat.shape[0]\n",
    "    p = dat.shape[1] - 1\n",
    "    keyDict = {\"coefficient\", \"lb\", \"ub\", \"nreg\"}\n",
    "    output = dict([(key, []) for key in keyDict])\n",
    "    #First Lasso\n",
    "    lasso1=lasso_wrapper_parallel(b_start=np.ones(p-1), y=dat.Y, X=dat[dat.drop(['Y','X1'], axis=1).columns].to_numpy(), k_fold=True, num_k=10)\n",
    "    #List of covariates from the first lasso\n",
    "    cov1 = dat[dat.drop(['Y'], axis=1).columns].columns[np.nonzero(lasso1[2][\"estimate\"][-1])[0].tolist()]\n",
    "    \n",
    "    #Second Lasso\n",
    "    lasso2=lasso_wrapper_parallel(b_start=np.ones(p-1), y=dat.X1, X=dat[dat.drop(['Y','X1'], axis=1).columns].to_numpy(), k_fold=True, num_k=10)\n",
    "    #List of covariates from the second lasso\n",
    "    cov2 = dat[dat.drop(['Y'], axis=1).columns].columns[np.nonzero(lasso2[2][\"estimate\"][-1])[0].tolist()]\n",
    "    \n",
    "    #Covariates from first or second lasso \n",
    "    X = dat.loc[:, dat.columns.isin(cov1) | dat.columns.isin(cov2)]\n",
    "    #OLS\n",
    "    mod = sm.OLS(dat.Y, X)\n",
    "    res = mod.fit() \n",
    "    output['coefficient']=res.params[0]\n",
    "    output['lb']=res.conf_int(alpha=alpha, cols=None)[0][0]\n",
    "    output['ub']=res.conf_int(alpha=alpha, cols=None)[1][0]\n",
    "    output['nreg']=res.params.shape[0]-1\n",
    "    \n",
    "    return output\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tugce\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:178: UserWarning: evaluating in Python space because the '*' operator is not supported by numexpr for the bool dtype, use '&' instead\n",
      "  f\"evaluating in Python space because the {repr(op_str)} \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      N  coverageProb  meanAdditionalRegressors\n",
      "0   100           1.0                       2.0\n",
      "1   200           0.8                       2.0\n",
      "2   400           1.0                       2.0\n",
      "3   700           1.0                       2.0\n",
      "4  1000           0.9                       2.0\n"
     ]
    }
   ],
   "source": [
    "def doubleLasso_simulateCoefficients_cvLambda(N, p, rho, alpha, S):\n",
    "  \n",
    "    # prepare storage space\n",
    "    results = pd.DataFrame(columns=(\"coefficient\",\"lb\",\"ub\",\"nreg\"))\n",
    "\n",
    "  \n",
    "    # perform Monte Carlo simulation\n",
    "    for k in range(S):\n",
    "        dat = sim_generateData2(N, p, rho)\n",
    "        results=pd.concat([results,pd.DataFrame(doubleLasso_estimateCoefficients_cvLambda(dat, alpha),index=[k])])\n",
    "\n",
    "  \n",
    "    return(results)\n",
    "\n",
    "\n",
    "\n",
    "# set seed\n",
    "random.seed(100)\n",
    "\n",
    "# specify model\n",
    "# list of N values\n",
    "N_array = np.array((100, 200, 400, 700, 1000))\n",
    "# number of regressors\n",
    "p = 3\n",
    "# correlation between X's\n",
    "rho = 0.9\n",
    "# significance level\n",
    "alpha = 0.05\n",
    "# number of Monte Carlo replications\n",
    "S = 1000\n",
    "\n",
    "result = pd.DataFrame(columns=(\"N\",\"coverageProb\",\"meanAdditionalRegressors\"))\n",
    "k=0\n",
    "# perform simulation\n",
    "for i in N_array:\n",
    "\n",
    "    # simulate pretest estimators\n",
    "    results = doubleLasso_simulateCoefficients_cvLambda(N=i, p=p, rho=rho, alpha=alpha, S=S)\n",
    "    # check if each confidence interval contains the true value\n",
    "    includeTrueValue = (results['lb'] <= 1) * (1 <= results['ub'])\n",
    "    # return the result\n",
    "    result=pd.concat([result,pd.DataFrame({\"N\":i,\"coverageProb\":includeTrueValue.mean(),\"meanAdditionalRegressors\":results['nreg'].mean()},index=[k])])\n",
    "    k=k+1\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
