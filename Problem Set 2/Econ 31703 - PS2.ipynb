{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import njit, jit\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from numpy import random\n",
    "from numpy import linalg\n",
    "from numpy import matlib\n",
    "from scipy import sparse\n",
    "from scipy import stats\n",
    "from scipy.optimize import minimize\n",
    "import statsmodels.api as sm\n",
    "import matplotlib\n",
    "import itertools as it\n",
    "from matplotlib import rc\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "matplotlib.rcParams['text.usetex'] = True\n",
    "matplotlib.rcParams['text.latex.preamble'] = [\n",
    "    r'\\usepackage{amssymb}',\n",
    "    r'\\usepackage{amsmath}',\n",
    "    r'\\usepackage{xcolor}',\n",
    "    r'\\renewcommand*\\familydefault{\\sfdefault}']\n",
    "matplotlib.rcParams['pgf.texsystem'] = 'pdflatex'\n",
    "matplotlib.rcParams['pgf.preamble']  = [\n",
    "    r'\\usepackage[utf8x]{inputenc}',\n",
    "    r'\\usepackage{amssymb}',\n",
    "    r'\\usepackage[T1]{fontenc}',\n",
    "    r'\\usepackage{amsmath}',\n",
    "    r'\\usepackage{sansmath}']\n",
    "\n",
    "from IPython.display import set_matplotlib_formats\n",
    "%matplotlib inline\n",
    "set_matplotlib_formats('svg')\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_objective(b, y, X, lmbda):\n",
    "    \n",
    "    \"\"\"\n",
    "        Function that accepts the guess for the parameter vector and LASSO penalty multipler λ, \n",
    "         and computes the LASSO objective function based on the input data.\n",
    "        :param b: Parameter vector.\n",
    "        :param y: Outcome variable, vector of size N.\n",
    "        :param X: Covariate variables (may or may not include ι), matrix of size N x P.\n",
    "        :param lmbda: LASSO penalty.        \n",
    "        :return: Objective function evaluated using inputs.\n",
    "    \"\"\"\n",
    "\n",
    "    # Return the objective function if matrix multiplication Xβ is compatible.\n",
    "    try:\n",
    "        obj = np.square(y - X @ b).sum() + lmbda * norm(b, ord=1)\n",
    "        return obj\n",
    "    except:\n",
    "        print(\"Error: The number of covariates is not compatible with given coefficient vector.\")\n",
    "        return np.inf       \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dualsol(bj, lmbda):\n",
    "    \"\"\"\n",
    "        Function that returns the solution for a single coordinate in the Cyclic\n",
    "         Coordinate Descent algorithm given the OLS coordinate estimate and the\n",
    "         LASSO penalty multipler.\n",
    "        :param bj: OLS estimate for coordinate j.\n",
    "        :param lmbda: LASSO penalty multiplier. \n",
    "        :return: LASSO coordinate estimate.\n",
    "    \"\"\"\n",
    "   \n",
    "    if bj < - lmbda:\n",
    "        return (bj + lmbda)\n",
    "    elif rho >  lamda:\n",
    "        return (bj - lmbda)\n",
    "    else: \n",
    "        return 0\n",
    "\n",
    "\n",
    "def lasso_cdg(bstart, y, X, lmbda, eps=1e-6, maxiter=1000, standardized=False):\n",
    "    \n",
    "    \"\"\"\n",
    "        Function that performs the LASSO estimation through the Cyclic Coordinate Descent algorithm.\n",
    "        :param b: Initial guess for the parameter vector (may or may not include b0, which will be trimmed out if so)\n",
    "        :param y: Outcome variable, vector of size N.\n",
    "        :param X: Covariate variables (may or may not include ι), matrix of size N x P.\n",
    "        :param lmbda: LASSO penalty multiplier.  \n",
    "        :param eps: Norm stopping criterion.\n",
    "        :param maxiter: Iteration number stopping criterion.\n",
    "        :param standardized: Indicator for whether the data has been standardized.\n",
    "        :return: List containing:\n",
    "            - :estimate: final coefficient vector estimate, \n",
    "            - :objectives: vector containing LASSO objective function values\n",
    "            - :steps: vector containing norm of difference in estimated parameter vectors\n",
    "            - :status: string regarding which stopping criterion was used.\n",
    "    \"\"\"\n",
    "    \n",
    "    p, N, b_guess = bstart.size, y.size, bstart\n",
    "       \n",
    "    if N != X.shape[0]:      \n",
    "        print(\"Error: Covariate matrix is incompatible with outcome variable.\")\n",
    "        return None\n",
    "    elif p != X.shape[1]:\n",
    "        print(\"Error: Covariate matrix is incompatible with parameter vector.\")\n",
    "        return None\n",
    "    \n",
    "\n",
    "        \n",
    "    # Standardize data if not done so\n",
    "    if standardized is False:\n",
    "        X_mean, y_mean = X.mean(axis=0), y.mean()\n",
    "        X_std, y_std = X.std(axis=0), y.std()\n",
    "        X, y = zscore(X, axis=0), zscore(y) \n",
    "        \n",
    "    # LASSO objective\n",
    "    lasso_obj = lambda b : lasso_objective(b, y, X, lmbda)\n",
    "        \n",
    "    keyDict = {\"estimate\", \"objectives\", \"steps\", \"status\"}\n",
    "    output = dict([(key, []) for key in keyDict])\n",
    "    \n",
    "    niter, dist = 1, 1\n",
    "    \n",
    "    # While loop to perform LASSO minimization using two stopping criterion.\n",
    "    while niter < maxiter and dist > eps:\n",
    "        \n",
    "        b_old = b_guess\n",
    "        \n",
    "        for j in np.arange(0, p):\n",
    "            \n",
    "            # Extract j^{th} covariate vector\n",
    "            Xj = X[:,j].reshape(-1,1)\n",
    "            \n",
    "            # Compute OLS solution for β_j taking β_{-j} as given\n",
    "            bj = X_j.T @ (y - X @ b_guess + b_guess[j] * Xj)\n",
    "            \n",
    "            # Update guess for j^{th} coordinate using LASSO closed form solution under CDG\n",
    "            b_guess[j] = dualsol(bj, lmbda) \n",
    "            \n",
    "        b0 = y_mean - np.dot(X_mean, b_guess)            \n",
    "        \n",
    "        output[\"estimate\"].append(np.array([b0, b_guess]))\n",
    "        output[\"objectives\"].append(lasso_obj(b_guess))\n",
    "        output[\"steps\"].append(norm(b_old - b_guess, ord=np.inf))\n",
    "        \n",
    "        if norm(b_old - b_guess, ord=np.inf) < eps:\n",
    "            output[\"status\"] = \"convergence\"             \n",
    "            return output  \n",
    "                               \n",
    "    output[\"status\"] = \"maxiter exceed\"    \n",
    "    \n",
    "    return output\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_cdg_active(bstart,data,lmbda,epsilon=1e-06,maxiter=1000,standardized=False,cycle_len):\n",
    "    p_coeff = bstart.size\n",
    "    y = data[:,0]\n",
    "    X = data[:,np.arange(1,data[0,:].size)]\n",
    "    N,p = X.shape\n",
    "    if p!=p_coeff:\n",
    "        print(\"Error: Covariate number is not compatible with given coefficient vector\")\n",
    "        return\n",
    "    else:\n",
    "        if standardized==False:\n",
    "            X = X / (np.linalg.norm(X,axis = 0))\n",
    "        keyDict = {\"estimate\",\"objectives\",\"steps\",\"status\"}\n",
    "        output = dict([(key, []) for key in keyDict])\n",
    "        for i in range(maxiter):\n",
    "            if i%cycle_len==0:\n",
    "                for j in range(p):\n",
    "                    obj = lambda x : lasso_objective(np.hstack((bstart[0:j],x,bstart[j+1:p])),data,lmbda)\n",
    "                    res = minimize(obj, x0=bstart[j], method='Nelder-Mead')\n",
    "                    output[\"estimate\"] = np.hstack((bstart[0:j],res.x,bstart[j+1:p]))\n",
    "                    output[\"objectives\"] = res.fun\n",
    "                    output[\"steps\"] = np.linalg.norm(bstart-output[\"estimate\"],ord=np.inf)\n",
    "            else:\n",
    "                for j in np.nonzero(output[\"estimate\"])[0].tolist():\n",
    "                    obj = lambda x : lasso_objective(np.hstack((bstart[0:j],x,bstart[j+1:p])),data,lmbda)\n",
    "                    res = minimize(obj, x0=bstart[j], method='Nelder-Mead')\n",
    "                    output[\"estimate\"] = np.hstack((bstart[0:j],res.x,bstart[j+1:p]))\n",
    "                    output[\"objectives\"] = res.fun\n",
    "                    output[\"steps\"] = np.linalg.norm(bstart-output[\"estimate\"],ord=np.inf)\n",
    "            if output[\"steps\"]<epsilon:\n",
    "                output[\"status\"] = \"convergence\"\n",
    "                return output                             \n",
    "            bstart = output[\"estimate\"]                            \n",
    "        output[\"status\"] = \"maxiter exceed\"        \n",
    "        return output  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_generateData(N, rho): \n",
    "  # generate X\n",
    "    X1 = np.random.normal(size=N)\n",
    "    X2 = rho * X1 + np.sqrt(1-rho**2) * np.random.normal(size=N)\n",
    "  \n",
    "  # generate Y\n",
    "    Y = X1 + (1/np.sqrt(N)) * X2 + np.random.normal(size=N)\n",
    "    data = {'Y': Y, 'X1': X1, 'X2': X2}\n",
    "    df = pd.DataFrame (data, columns = ['Y','X1','X2'],index=range(N))\n",
    "\n",
    "  # return dataset\n",
    "    return(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretest_estimateCoefficients(dat, alpha):\n",
    "    # read dimensions\n",
    "    N = dat.shape[0]\n",
    "    dn= 1/(N**(1/4))\n",
    "    X=dat.loc[:, dat.columns.isin(['X1','X2'])]\n",
    "    mod = sm.OLS(dat.Y, X)\n",
    "    res = mod.fit()  \n",
    "    keyDict = {\"coefficient\",\"lb\",\"ub\",\"test\"}\n",
    "    output = dict([(key, []) for key in keyDict])\n",
    "    if np.abs(res.params[1])>dn:\n",
    "        output['coefficient']=res.params[0]\n",
    "        output['lb']=res.conf_int(alpha=alpha, cols=None)[0][0]\n",
    "        output['ub']=res.conf_int(alpha=alpha, cols=None)[1][0]\n",
    "        output['test']= False\n",
    "    else:\n",
    "        X=dat.X1\n",
    "        mod = sm.OLS(dat.Y, X)\n",
    "        res = mod.fit()  \n",
    "        output['coefficient']=res.params[0]\n",
    "        output['lb']=res.conf_int(alpha=alpha, cols=None)[0][0]\n",
    "        output['ub']=res.conf_int(alpha=alpha, cols=None)[1][0]\n",
    "        output['test']= True    \n",
    "    return output \n",
    "\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      N  coverageProb  shortModelSelectionProb\n",
      "0   100         0.845                    0.798\n",
      "1   200         0.835                    0.861\n",
      "2   400         0.853                    0.932\n",
      "3   700         0.846                    0.963\n",
      "4  1000         0.845                    0.983\n"
     ]
    }
   ],
   "source": [
    "def pretest_simulateCoefficients(N, rho, alpha, S):\n",
    "    results = pd.DataFrame(columns=(\"coefficient\",\"lb\",\"ub\",\"test\"))\n",
    "    # perform Monte Carlo simulation\n",
    "    for k in range(S): \n",
    "        dat = sim_generateData(N, rho)\n",
    "        results=pd.concat([results,pd.DataFrame(pretest_estimateCoefficients(dat, alpha),index=[k])])\n",
    "\n",
    "    return(results)\n",
    "\n",
    "# set seed\n",
    "random.seed(100)\n",
    "# specify model\n",
    "# list of N values\n",
    "N_array = np.array((100, 200, 400, 700, 1000))\n",
    "# correlation between X's\n",
    "rho = 0.9\n",
    "# significance level\n",
    "alpha = 0.05\n",
    "# number of Monte Carlo replications\n",
    "S = 1000\n",
    "\n",
    "result = pd.DataFrame(columns=(\"N\",\"coverageProb\",\"shortModelSelectionProb\"))\n",
    "k=0\n",
    "# perform simulation\n",
    "for i in N_array:\n",
    "\n",
    "    # simulate pretest estimators\n",
    "    results = pretest_simulateCoefficients(N=i, rho=rho, alpha=alpha, S=S)\n",
    "    # check if each confidence interval contains the true value\n",
    "    includeTrueValue = (results['lb'] <= 1) * (1 <= results['ub'])\n",
    "    # return the result\n",
    "    result=pd.concat([result,pd.DataFrame({\"N\":i,\"coverageProb\":includeTrueValue.mean(),\"shortModelSelectionProb\":results['test'].mean()},index=[k])])\n",
    "    k=k+1\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_generateData2(N, p, rho):\n",
    "    # generate X\n",
    "    X1 = np.random.normal(size=N)\n",
    "    Xp = (rho / (p-1)) * np.transpose([X1]*(p-1))+ np.sqrt(0.5 * (1-rho**2) / (p-1)) * np.random.normal(size=(N,p-1))\n",
    "    # generate Y\n",
    "    # bind Y and X\n",
    "    Y = X1 + ((1/np.sqrt(N)) * Xp).sum() + np.sqrt(0.5 * (1-rho**2)) * np.random.normal(size=N)\n",
    "    dat=pd.concat([pd.DataFrame(Y,columns=['Y']),pd.DataFrame(X1,columns=['X1']),pd.DataFrame(Xp,columns=[i + j for i, j in zip(['X']*(p-1),map(str,list(range(2,p+1))))])],axis=1)\n",
    "    \n",
    "    return(dat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doubleLasso_estimateCoefficients_fixedLambda(dat, lmbda, alpha):\n",
    "  \n",
    "    # read dimensions\n",
    "    N = dat.shape[0]\n",
    "    p = dat.shape[1] - 1\n",
    "  \n",
    "    \n",
    "    lasso1 = lasso_cdg(bstart=np.ones(p-1),y=dat.Y, X=dat[dat.drop(['Y','X1'], axis=1).columns],lmbda=lmbda[0])\n",
    "    cov1 = dat[dat.drop(['Y','X1'], axis=1).columns].columns[np.nonzero(lasso1[\"estimate\"])[0].tolist()]\n",
    "    \n",
    "    lasso2 = lasso_cdg(bstart=np.ones(p-1),y=dat.X1, X=dat[dat.drop(['Y','X1'], axis=1).columns],lmbda=lmbda[1])\n",
    "    cov2 = dat[dat.drop(['Y','X1'], axis=1).columns].columns[np.nonzero(lasso2[\"estimate\"])[0].tolist()]\n",
    "    \n",
    "    X = dat.loc[:, dat.columns.isin(['X1']) | dat.columns.isin(cov1) | dat.columns.isin(cov2)]\n",
    "    mod = sm.OLS(dat.Y, X)\n",
    "    res = mod.fit() \n",
    "    output['coefficient']=res.params[0]\n",
    "    output['lb']=res.conf_int(alpha=alpha, cols=None)[0][0]\n",
    "    output['ub']=res.conf_int(alpha=alpha, cols=None)[1][0]\n",
    "    output['nreg']=res.params.shape[0]-1\n",
    "    \n",
    "    return output\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "lasso_cdg() missing 1 required positional argument: 'lmbda'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-f11b7bf990b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;31m# simulate pretest estimators\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdoubleLasso_simulateCoefficients_fixedLambda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrho\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrho\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlmbda\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlmbda\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mS\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m     \u001b[1;31m# check if each confidence interval contains the true value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[0mincludeTrueValue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lb'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ub'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-f11b7bf990b7>\u001b[0m in \u001b[0;36mdoubleLasso_simulateCoefficients_fixedLambda\u001b[1;34m(N, p, rho, lmbda, alpha, S)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mdat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msim_generateData2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrho\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mresults\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoubleLasso_estimateCoefficients_fixedLambda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlmbda\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-3bfd1cdb9eac>\u001b[0m in \u001b[0;36mdoubleLasso_estimateCoefficients_fixedLambda\u001b[1;34m(dat, lmbda, alpha)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mlasso1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlasso_cdg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'X1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlmbda\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mcov1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'X1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlasso1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"estimate\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: lasso_cdg() missing 1 required positional argument: 'lmbda'"
     ]
    }
   ],
   "source": [
    "def doubleLasso_simulateCoefficients_fixedLambda(N, p, rho, lmbda, alpha, S):\n",
    "  \n",
    "    # prepare storage space\n",
    "    results = pd.DataFrame(columns=(\"coefficient\",\"lb\",\"ub\",\"nreg\"))\n",
    "\n",
    "  \n",
    "    # perform Monte Carlo simulation\n",
    "    for k in range(S):\n",
    "        dat = sim_generateData2(N, p, rho)\n",
    "        results=pd.concat([results,pd.DataFrame(doubleLasso_estimateCoefficients_fixedLambda(dat, lmbda, alpha),index=[k])])\n",
    "\n",
    "  \n",
    "    return(results)\n",
    "\n",
    "\n",
    "\n",
    "# set seed\n",
    "random.seed(100)\n",
    "\n",
    "# specify model\n",
    "# list of N values\n",
    "N_array = np.array((100, 200, 400, 700, 1000))\n",
    "# number of regressors\n",
    "p = 3\n",
    "# correlation between X's\n",
    "rho = 0.9\n",
    "# lasso penalty multipliers\n",
    "lmbda = np.array((0.7, 0.7))\n",
    "# significance level\n",
    "alpha = 0.05\n",
    "# number of Monte Carlo replications\n",
    "S = 1000\n",
    "\n",
    "result = pd.DataFrame(columns=(\"N\",\"coverageProb\",\"meanAdditionalRegressors\"))\n",
    "k=0\n",
    "# perform simulation\n",
    "for i in N_array:\n",
    "\n",
    "    # simulate pretest estimators\n",
    "    results = doubleLasso_simulateCoefficients_fixedLambda(N=i, p=p, rho=rho, lmbda=lmbda, alpha=alpha, S=S)\n",
    "    # check if each confidence interval contains the true value\n",
    "    includeTrueValue = (results['lb'] <= 1) * (1 <= results['ub'])\n",
    "    # return the result\n",
    "    result=pd.concat([result,pd.DataFrame({\"N\":i,\"coverageProb\":includeTrueValue.mean(),\"shortModelSelectionProb\":results['nreg'].mean()},index=[k])])\n",
    "    k=k+1\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doubleLasso_estimateCoefficients_cvLambda(dat, alpha):\n",
    " \n",
    "    # read dimensions\n",
    "    N = dat.shape[0]\n",
    "    p = dat.shape[1] - 1\n",
    "  \n",
    "    lasso1 = lasso_cdg_kfold(np.ones(p-1),dat[dat.drop(['X1'], axis=1).columns])\n",
    "    cov1 = dat[dat.drop(['X1'], axis=1).columns].columns[np.nonzero(lasso1[\"estimate\"])[0].tolist()]\n",
    "    \n",
    "    lasso2 = lasso_cdg_kfold(np.ones(p-1),dat[dat.drop(['Y'], axis=1).columns])\n",
    "    cov2 = dat[dat.drop(['Y'], axis=1).columns].columns[np.nonzero(lasso2[\"estimate\"])[0].tolist()]\n",
    "    \n",
    "    X = dat.loc[:, dat.columns.isin(['X1']) | dat.columns.isin(cov1) | dat.columns.isin(cov2)]\n",
    "    mod = sm.OLS(dat.Y, X)\n",
    "    res = mod.fit() \n",
    "    output['coefficient']=res.params[0]\n",
    "    output['lb']=res.conf_int(alpha=alpha, cols=None)[0][0]\n",
    "    output['ub']=res.conf_int(alpha=alpha, cols=None)[1][0]\n",
    "    output['nreg']=res.params.shape[0]-1\n",
    "    \n",
    "    return output\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doubleLasso_simulateCoefficients_cvLambda(N, p, rho, alpha, S):\n",
    "  \n",
    "    # prepare storage space\n",
    "    results = pd.DataFrame(columns=(\"coefficient\",\"lb\",\"ub\",\"nreg\"))\n",
    "\n",
    "  \n",
    "    # perform Monte Carlo simulation\n",
    "    for k in range(S):\n",
    "        dat = sim_generateData2(N, p, rho)\n",
    "        results=pd.concat([results,pd.DataFrame(doubleLasso_estimateCoefficients_cvLambda(dat, lmbda, alpha),index=[k])])\n",
    "\n",
    "  \n",
    "    return(results)\n",
    "\n",
    "\n",
    "\n",
    "# set seed\n",
    "random.seed(100)\n",
    "\n",
    "# specify model\n",
    "# list of N values\n",
    "N_array = np.array((100, 200, 400, 700, 1000))\n",
    "# number of regressors\n",
    " p = 3\n",
    "# correlation between X's\n",
    "rho = 0.9\n",
    "# significance level\n",
    "alpha = 0.05\n",
    "# number of Monte Carlo replications\n",
    "S = 1000\n",
    "\n",
    "result = pd.DataFrame(columns=(\"N\",\"coverageProb\",\"meanAdditionalRegressors\"))\n",
    "k=0\n",
    "# perform simulation\n",
    "for i in N_array:\n",
    "\n",
    "    # simulate pretest estimators\n",
    "    results = doubleLasso_simulateCoefficients_cvLambda(N=i, p=p, rho=rho, alpha=alpha, S=S)\n",
    "    # check if each confidence interval contains the true value\n",
    "    includeTrueValue = (results['lb'] <= 1) * (1 <= results['ub'])\n",
    "    # return the result\n",
    "    result=pd.concat([result,pd.DataFrame({\"N\":i,\"coverageProb\":includeTrueValue.mean(),\"shortModelSelectionProb\":results['nreg'].mean()},index=[k])])\n",
    "    k=k+1\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
