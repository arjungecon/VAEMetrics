{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numba import njit, jit\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from matplotlib import rc\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import norm, zscore\n",
    "import scipy as sp\n",
    "from numpy import random, linalg\n",
    "from scipy import sparse, stats\n",
    "import itertools as it\n",
    "from sklearn.preprocessing import StandardScaler as scaler\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "matplotlib.rcParams['text.usetex'] = True\n",
    "matplotlib.rcParams['text.latex.preamble'] = [\n",
    "    r'\\usepackage{amssymb}',\n",
    "    r'\\usepackage{amsmath}',\n",
    "    r'\\usepackage{xcolor}',\n",
    "    r'\\renewcommand*\\familydefault{\\sfdefault}']\n",
    "matplotlib.rcParams['pgf.texsystem'] = 'pdflatex'\n",
    "matplotlib.rcParams['pgf.preamble'] = [\n",
    "    r'\\usepackage[utf8x]{inputenc}',\n",
    "    r'\\usepackage{amssymb}',\n",
    "    r'\\usepackage[T1]{fontenc}',\n",
    "    r'\\usepackage{amsmath}',\n",
    "    r'\\usepackage{sansmath}']\n",
    "\n",
    "inv, ax, norm = np.linalg.inv, np.newaxis, np.linalg.norm\n",
    "randint = np.random.randint\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_objective(b, y, X, lmbda):\n",
    "\n",
    "    # Question 1 Part A\n",
    "\n",
    "    \"\"\"\n",
    "        Function that accepts the guess for the parameter vector and LASSO penalty multipler λ,\n",
    "         and computes the LASSO objective function based on the input data.\n",
    "        :param b: Parameter vector.\n",
    "        :param y: Outcome variable, vector of size N.\n",
    "        :param X: Covariate variables (may or may not include ι), matrix of size N x P.\n",
    "        :param lmbda: LASSO penalty.\n",
    "        :return: Objective function evaluated using inputs.\n",
    "    \"\"\"\n",
    "\n",
    "    # Return the objective function if matrix multiplication Xβ is compatible.\n",
    "    try:\n",
    "        obj = np.square(y - X @ b).sum()/2 + lmbda * norm(b, ord=1)\n",
    "        return obj\n",
    "    except:\n",
    "        print(\"Error: The number of covariates is not compatible with given coefficient vector.\")\n",
    "        return np.inf\n",
    "\n",
    "\n",
    "def dual_sol(bj, lmbda):\n",
    "\n",
    "    \"\"\"\n",
    "        Function that returns the solution for a single coordinate in the Cyclic\n",
    "         Coordinate Descent algorithm given the OLS coordinate estimate and the\n",
    "         LASSO penalty multipler.\n",
    "        :param bj: OLS estimate for coordinate j.\n",
    "        :param lmbda: LASSO penalty multiplier.\n",
    "        :return: LASSO coordinate estimate.\n",
    "    \"\"\"\n",
    "\n",
    "    if bj < - lmbda:\n",
    "        return bj + lmbda\n",
    "    elif bj > lmbda:\n",
    "        return bj - lmbda\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def lambda_zero(y, X, standardized=False):\n",
    "\n",
    "    # Question 1 Part D\n",
    "\n",
    "    \"\"\"\n",
    "        Function that computes the smallest penalty at which the LASSO estimate is exactly equal to zero.\n",
    "        :param y: Outcome variable, vector of size N.\n",
    "        :param X: Covariate variables (may or may not include ι), matrix of size N x P.\n",
    "        :param standardized: Indicator for whether the data has been standardized.\n",
    "        :return: The lambda penalty.\n",
    "    \"\"\"\n",
    "\n",
    "    if standardized is False:\n",
    "        X, y = zscore(X, axis=0), zscore(y)\n",
    "\n",
    "    lmbda_max = np.max(X.T @ y)\n",
    "\n",
    "    return lmbda_max\n",
    "\n",
    "\n",
    "def lasso_cdg(b_start, y, X, lmbda, eps=1e-6, max_iter=1000, standardized=False, \n",
    "              active_set=False, active_set_cycle=10, safe=False):\n",
    "\n",
    "    # Question 1 Part B + C + E\n",
    "\n",
    "    \"\"\"\n",
    "        Function that performs the LASSO estimation through the Cyclic Coordinate Descent algorithm. Additional\n",
    "         options for using the Active Set Strategy and the SAFE algorithm are provided.\n",
    "\n",
    "        :param b_start: Initial guess for the parameter vector (may or may not include b0, which will be \n",
    "         trimmed out if so)\n",
    "        :param y: Outcome variable, vector of size N.\n",
    "        :param X: Covariate variables (may or may not include ι), matrix of size N x P.\n",
    "        :param lmbda: LASSO penalty multiplier.\n",
    "        :param eps: Norm stopping criterion.\n",
    "        :param max_iter: Iteration number stopping criterion.\n",
    "        :param standardized: Indicator for whether the data has been standardized.\n",
    "\n",
    "        :param active_set: Option for using the Active Set strategy to increase the speed of the algorithm.\n",
    "        :param active_set_cycle: The frequency at which all covariates are updated in CDG rather than those in\n",
    "         the Active Set. This option is not used if \"active_set\" is False.\n",
    "        :param safe: Option for using the SAFE strategy to discard covariates.\n",
    "\n",
    "        :return: List containing:\n",
    "            - :estimate: final coefficient vector estimate,\n",
    "            - :objectives: vector containing LASSO objective function values\n",
    "            - :steps: vector containing norm of difference in estimated parameter vectors\n",
    "            - :status: string regarding which stopping criterion was used.\n",
    "    \"\"\"\n",
    "\n",
    "    p, N, b_guess = b_start.size, y.size, b_start\n",
    "\n",
    "    if N != X.shape[0]:\n",
    "        print(\"Error: Covariate matrix is incompatible with outcome variable.\")\n",
    "        return None\n",
    "    elif p != X.shape[1]:\n",
    "        print(\"Error: Covariate matrix is incompatible with parameter vector.\")\n",
    "        return None\n",
    "\n",
    "    # Detect if a constant term is included\n",
    "    iota = (X[:, 0] == X[:, 0].mean()).all()\n",
    "\n",
    "    # Trim out constant term\n",
    "    if iota:\n",
    "        X, b_guess = X[:, 1:], b_guess[1:]\n",
    "        p = p - 1\n",
    "\n",
    "    # Standardize data if not done so\n",
    "    if standardized is False:\n",
    "        X_mean, y_mean = X.mean(axis=0), y.mean()\n",
    "        X_std, y_std = X.std(axis=0), y.std()\n",
    "        X, y = zscore(X, axis=0), zscore(y)\n",
    "\n",
    "    # LASSO objective\n",
    "    lasso_obj = lambda b: lasso_objective(b, y, X, lmbda)\n",
    "\n",
    "    # Default options for Active Set and SAFE strategies\n",
    "    active_range = lambda x: np.arange(0, p)\n",
    "    safe_range = np.arange(0, p)\n",
    "\n",
    "    # Implementing Active Set Strategy\n",
    "    if active_set:\n",
    "        active_range = lambda x: np.where(x != 0)[0]\n",
    "\n",
    "    # Implementing SAFE Strategy\n",
    "    if safe:\n",
    "\n",
    "        # Find lambda_max: minimum value of lambda such that LASSO estimate is zero\n",
    "        lmbda_max = lambda_zero(y=y, X=X, standardized=True)\n",
    "\n",
    "        # Assign Boolean condition for covariates that can be discarded using the SAFE condition\n",
    "        safe_condition = (X.T @ y).squeeze() < lmbda_max - norm(X, axis=0) * norm(y) * (lmbda_max - lmbda)/lmbda\n",
    "\n",
    "        # Find indices corresponding to \"relevant\" covariates\n",
    "        safe_range = np.where(~safe_condition)[0]\n",
    "\n",
    "        # Set discarded covariates to have zero estimate under LASSO\n",
    "        b_guess[safe_condition] = 0\n",
    "\n",
    "    keyDict = {\"estimate\", \"objectives\", \"steps\", \"status\"}\n",
    "    output = dict([(key, []) for key in keyDict])\n",
    "\n",
    "    niter, dist = 0, 1000\n",
    "\n",
    "    # While loop to perform LASSO minimization using two stopping criterion.\n",
    "    while niter < max_iter and dist > eps:\n",
    "\n",
    "        b_update = np.zeros(shape=b_guess.shape)\n",
    "\n",
    "        # Active set strategy\n",
    "        if niter % active_set_cycle == 0:\n",
    "            range_j = safe_range\n",
    "        else:\n",
    "            range_j = active_range(b_guess)\n",
    "\n",
    "        for j in range_j:\n",
    "\n",
    "            # Extract j^{th} covariate vector\n",
    "            Xj = X[:, j].reshape(-1, 1)\n",
    "\n",
    "            # Compute OLS solution for β_j taking β_{-j} as given\n",
    "            bj = b_guess[j] + Xj.T @ (y - X @ b_guess)/N\n",
    "\n",
    "            # Update guess for j^{th} coordinate using LASSO closed form solution under CDG\n",
    "            b_update[j] = dual_sol(bj, lmbda)\n",
    "\n",
    "        b0 = y_mean - np.dot(X_mean, b_update)\n",
    "        dist = norm(b_update - b_guess, ord=np.inf)\n",
    "\n",
    "        output[\"estimate\"].append(np.append(b0,b_update))\n",
    "        output[\"objectives\"].append(lasso_obj(b_update))\n",
    "        output[\"steps\"].append(dist)\n",
    "\n",
    "        niter = niter + 1\n",
    "        b_guess = b_update\n",
    "\n",
    "        if dist <= eps:\n",
    "            output[\"status\"] = \"convergence\"\n",
    "\n",
    "    if niter >= max_iter:\n",
    "        output[\"status\"] = \"max_iter exceed\"\n",
    "\n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_generateData(N, rho): \n",
    "  # generate X\n",
    "    X1 = np.random.normal(size=N)\n",
    "    X2 = rho * X1 + np.sqrt(1-rho**2) * np.random.normal(size=N)\n",
    "  \n",
    "  # generate Y\n",
    "    Y = X1 + (1/np.sqrt(N)) * X2 + np.random.normal(size=N)\n",
    "    data = {'Y': Y, 'X1': X1, 'X2': X2}\n",
    "    df = pd.DataFrame (data, columns = ['Y','X1','X2'],index=range(N))\n",
    "\n",
    "  # return dataset\n",
    "    return(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretest_estimateCoefficients(dat, alpha):\n",
    "    # read dimensions\n",
    "    N = dat.shape[0]\n",
    "    dn= 1/(N**(1/4))\n",
    "    X=dat.loc[:, dat.columns.isin(['X1','X2'])]\n",
    "    mod = sm.OLS(dat.Y, X)\n",
    "    res = mod.fit()  \n",
    "    keyDict = {\"coefficient\",\"lb\",\"ub\",\"test\"}\n",
    "    output = dict([(key, []) for key in keyDict])\n",
    "    if np.abs(res.params[1])>dn:\n",
    "        output['coefficient']=res.params[0]\n",
    "        output['lb']=res.conf_int(alpha=alpha, cols=None)[0][0]\n",
    "        output['ub']=res.conf_int(alpha=alpha, cols=None)[1][0]\n",
    "        output['test']= False\n",
    "    else:\n",
    "        X=dat.X1\n",
    "        mod = sm.OLS(dat.Y, X)\n",
    "        res = mod.fit()  \n",
    "        output['coefficient']=res.params[0]\n",
    "        output['lb']=res.conf_int(alpha=alpha, cols=None)[0][0]\n",
    "        output['ub']=res.conf_int(alpha=alpha, cols=None)[1][0]\n",
    "        output['test']= True    \n",
    "    return output \n",
    "\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      N  coverageProb  shortModelSelectionProb\n",
      "0   100         0.845                    0.798\n",
      "1   200         0.835                    0.861\n",
      "2   400         0.853                    0.932\n",
      "3   700         0.846                    0.963\n",
      "4  1000         0.845                    0.983\n"
     ]
    }
   ],
   "source": [
    "def pretest_simulateCoefficients(N, rho, alpha, S):\n",
    "    results = pd.DataFrame(columns=(\"coefficient\",\"lb\",\"ub\",\"test\"))\n",
    "    # perform Monte Carlo simulation\n",
    "    for k in range(S): \n",
    "        dat = sim_generateData(N, rho)\n",
    "        results=pd.concat([results,pd.DataFrame(pretest_estimateCoefficients(dat, alpha),index=[k])])\n",
    "\n",
    "    return(results)\n",
    "\n",
    "# set seed\n",
    "random.seed(100)\n",
    "# specify model\n",
    "# list of N values\n",
    "N_array = np.array((100, 200, 400, 700, 1000))\n",
    "# correlation between X's\n",
    "rho = 0.9\n",
    "# significance level\n",
    "alpha = 0.05\n",
    "# number of Monte Carlo replications\n",
    "S = 1000\n",
    "\n",
    "result = pd.DataFrame(columns=(\"N\",\"coverageProb\",\"shortModelSelectionProb\"))\n",
    "k=0\n",
    "# perform simulation\n",
    "for i in N_array:\n",
    "\n",
    "    # simulate pretest estimators\n",
    "    results = pretest_simulateCoefficients(N=i, rho=rho, alpha=alpha, S=S)\n",
    "    # check if each confidence interval contains the true value\n",
    "    includeTrueValue = (results['lb'] <= 1) * (1 <= results['ub'])\n",
    "    # return the result\n",
    "    result=pd.concat([result,pd.DataFrame({\"N\":i,\"coverageProb\":includeTrueValue.mean(),\"shortModelSelectionProb\":results['test'].mean()},index=[k])])\n",
    "    k=k+1\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_generateData2(N, p, rho):\n",
    "    # generate X\n",
    "    X1 = np.random.normal(size=N)\n",
    "    Xp = (rho / (p-1)) * np.transpose([X1]*(p-1))+ np.sqrt(0.5 * (1-rho**2) / (p-1)) * np.random.normal(size=(N,p-1))\n",
    "    # generate Y\n",
    "    # bind Y and X\n",
    "    Y = X1 + ((1/np.sqrt(N)) * Xp).sum() + np.sqrt(0.5 * (1-rho**2)) * np.random.normal(size=N)\n",
    "    dat=pd.concat([pd.DataFrame(Y,columns=['Y']),pd.DataFrame(X1,columns=['X1']),pd.DataFrame(Xp,columns=[i + j for i, j in zip(['X']*(p-1),map(str,list(range(2,p+1))))])],axis=1)\n",
    "    \n",
    "    return(dat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doubleLasso_estimateCoefficients_fixedLambda(dat, lmbda, alpha):\n",
    "  \n",
    "    # read dimensions\n",
    "    N = dat.shape[0]\n",
    "    p = dat.shape[1] - 1\n",
    "    keyDict = {\"coefficient\", \"lb\", \"ub\", \"nreg\"}\n",
    "    output = dict([(key, []) for key in keyDict])\n",
    "    \n",
    "    #First Lasso\n",
    "    lasso1 = lasso_cdg(b_start=np.ones(p-1),y=dat.Y, X=dat[dat.drop(['Y','X1'], axis=1).columns].to_numpy(),lmbda=lmbda[0])\n",
    "    #List of covariates from the first lasso\n",
    "    cov1 = dat[dat.drop(['Y'], axis=1).columns].columns[np.nonzero(lasso1[\"estimate\"][-1])[0].tolist()]\n",
    "    \n",
    "    #Second Lasso\n",
    "    lasso2 = lasso_cdg(b_start=np.ones(p-1),y=dat.X1, X=dat[dat.drop(['Y','X1'], axis=1).columns].to_numpy(),lmbda=lmbda[1])\n",
    "    #List of covariates from the second lasso\n",
    "    cov2 = dat[dat.drop(['Y'], axis=1).columns].columns[np.nonzero(lasso2[\"estimate\"][-1])[0].tolist()]\n",
    "    \n",
    "    #Covariates from first or second lasso \n",
    "    X = dat.loc[:, dat.columns.isin(cov1) | dat.columns.isin(cov2)]\n",
    "    #OLS\n",
    "    mod = sm.OLS(dat.Y, X)\n",
    "    res = mod.fit() \n",
    "    output['coefficient']=res.params[0]\n",
    "    output['lb']=res.conf_int(alpha=alpha, cols=None)[0][0]\n",
    "    output['ub']=res.conf_int(alpha=alpha, cols=None)[1][0]\n",
    "    output['nreg']=res.params.shape[0]-1\n",
    "    \n",
    "    return output\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      N  coverageProb  shortModelSelectionProb\n",
      "0   100         0.944                    1.956\n",
      "1   200         0.951                    1.996\n",
      "2   400         0.949                    2.000\n",
      "3   700         0.957                    2.000\n",
      "4  1000         0.963                    2.000\n"
     ]
    }
   ],
   "source": [
    "def doubleLasso_simulateCoefficients_fixedLambda(N, p, rho, lmbda, alpha, S):\n",
    "  \n",
    "    # prepare storage space\n",
    "    results = pd.DataFrame(columns=(\"coefficient\",\"lb\",\"ub\",\"nreg\"))\n",
    "\n",
    "  \n",
    "    # perform Monte Carlo simulation\n",
    "    for k in range(S):\n",
    "        dat = sim_generateData2(N, p, rho)\n",
    "        results=pd.concat([results,pd.DataFrame(doubleLasso_estimateCoefficients_fixedLambda(dat, lmbda, alpha),index=[k])])\n",
    "\n",
    "  \n",
    "    return(results)\n",
    "\n",
    "\n",
    "\n",
    "# set seed\n",
    "random.seed(100)\n",
    "\n",
    "# specify model\n",
    "# list of N values\n",
    "N_array = np.array((100, 200, 400, 700, 1000))\n",
    "# number of regressors\n",
    "p = 3\n",
    "# correlation between X's\n",
    "rho = 0.9\n",
    "# lasso penalty multipliers\n",
    "lmbda = np.array((0.7, 0.7))\n",
    "# significance level\n",
    "alpha = 0.05\n",
    "# number of Monte Carlo replications\n",
    "S = 1000\n",
    "\n",
    "result = pd.DataFrame(columns=(\"N\",\"coverageProb\",\"meanAdditionalRegressors\"))\n",
    "k=0\n",
    "# perform simulation\n",
    "for i in N_array:\n",
    "\n",
    "    # simulate pretest estimators\n",
    "    results = doubleLasso_simulateCoefficients_fixedLambda(N=i, p=p, rho=rho, lmbda=lmbda, alpha=alpha, S=S)\n",
    "    # check if each confidence interval contains the true value\n",
    "    includeTrueValue = (results['lb'] <= 1) * (1 <= results['ub'])\n",
    "    # return the result\n",
    "    result=pd.concat([result,pd.DataFrame({\"N\":i,\"coverageProb\":includeTrueValue.mean(),\"meanAdditionalRegressors\":results['nreg'].mean()},index=[k])])\n",
    "    k=k+1\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doubleLasso_estimateCoefficients_cvLambda(dat, alpha):\n",
    " \n",
    "    # read dimensions\n",
    "    N = dat.shape[0]\n",
    "    p = dat.shape[1] - 1\n",
    "  \n",
    "    #First Lasso\n",
    "    lasso1 = lasso_cdg_kfold(b_start=np.ones(p-1),y=dat.Y, X=dat[dat.drop(['Y','X1'], axis=1).columns].to_numpy())\n",
    "    #List of covariates from the first lasso\n",
    "    cov1 = dat[dat.drop(['Y'], axis=1).columns].columns[np.nonzero(lasso1[\"estimate\"][-1])[0].tolist()]\n",
    "    \n",
    "    #Second Lasso\n",
    "    lasso2 = lasso_cdg_kfold(b_start=np.ones(p-1),y=dat.X1, X=dat[dat.drop(['Y','X1'], axis=1).columns].to_numpy())\n",
    "    #List of covariates from the second lasso\n",
    "    cov2 = dat[dat.drop(['Y'], axis=1).columns].columns[np.nonzero(lasso2[\"estimate\"][-1])[0].tolist()]\n",
    "    \n",
    "    #Covariates from first or second lasso \n",
    "    X = dat.loc[:, dat.columns.isin(cov1) | dat.columns.isin(cov2)]\n",
    "    #OLS\n",
    "    mod = sm.OLS(dat.Y, X)\n",
    "    res = mod.fit() \n",
    "    output['coefficient']=res.params[0]\n",
    "    output['lb']=res.conf_int(alpha=alpha, cols=None)[0][0]\n",
    "    output['ub']=res.conf_int(alpha=alpha, cols=None)[1][0]\n",
    "    output['nreg']=res.params.shape[0]-1\n",
    "    \n",
    "    return output\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doubleLasso_simulateCoefficients_cvLambda(N, p, rho, alpha, S):\n",
    "  \n",
    "    # prepare storage space\n",
    "    results = pd.DataFrame(columns=(\"coefficient\",\"lb\",\"ub\",\"nreg\"))\n",
    "\n",
    "  \n",
    "    # perform Monte Carlo simulation\n",
    "    for k in range(S):\n",
    "        dat = sim_generateData2(N, p, rho)\n",
    "        results=pd.concat([results,pd.DataFrame(doubleLasso_estimateCoefficients_cvLambda(dat, lmbda, alpha),index=[k])])\n",
    "\n",
    "  \n",
    "    return(results)\n",
    "\n",
    "\n",
    "\n",
    "# set seed\n",
    "random.seed(100)\n",
    "\n",
    "# specify model\n",
    "# list of N values\n",
    "N_array = np.array((100, 200, 400, 700, 1000))\n",
    "# number of regressors\n",
    " p = 3\n",
    "# correlation between X's\n",
    "rho = 0.9\n",
    "# significance level\n",
    "alpha = 0.05\n",
    "# number of Monte Carlo replications\n",
    "S = 1000\n",
    "\n",
    "result = pd.DataFrame(columns=(\"N\",\"coverageProb\",\"meanAdditionalRegressors\"))\n",
    "k=0\n",
    "# perform simulation\n",
    "for i in N_array:\n",
    "\n",
    "    # simulate pretest estimators\n",
    "    results = doubleLasso_simulateCoefficients_cvLambda(N=i, p=p, rho=rho, alpha=alpha, S=S)\n",
    "    # check if each confidence interval contains the true value\n",
    "    includeTrueValue = (results['lb'] <= 1) * (1 <= results['ub'])\n",
    "    # return the result\n",
    "    result=pd.concat([result,pd.DataFrame({\"N\":i,\"coverageProb\":includeTrueValue.mean(),\"meanAdditionalRegressors\":results['nreg'].mean()},index=[k])])\n",
    "    k=k+1\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
